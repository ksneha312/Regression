{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Q1:-What is Simple Linear Regression?**\n",
        "\n",
        "**Ans:-**\n",
        "Simple Linear Regression is a fundamental statistical and machine learning technique used to model the relationship between two variables: a dependent variable (or target) and an independent variable (or predictor). The relationship is represented by a straight line, making it \"linear.\"\n",
        "\n",
        "**Q2:-What are the key assumptions of Simple Linear Regression?**\n",
        "\n",
        "**Ans:-**\n",
        "In Simple Linear Regression, several key assumptions are made to ensure that the model produces reliable and valid results. These assumptions are critical because if they are violated, the predictions and inferences made by the model could be misleading. Here are the main assumptions:\n",
        "\n",
        "**1. Linearity:**\n",
        "The relationship between the independent variable (\n",
        "x) and the dependent variable (\n",
        "y) is assumed to be linear. This means that changes in the independent variable cause proportional changes in the dependent variable.\n",
        "Mathematically, this is represented by the equation:\n",
        "y=mx+b\n",
        "where\n",
        "ğ‘š\n",
        "m is the slope and\n",
        "ğ‘\n",
        "b is the intercept.\n",
        "\n",
        "**2. Independence of Errors:**\n",
        "The residuals (the differences between the observed and predicted values) should be independent of each other.\n",
        "This assumption means that the error for one data point does not influence the error of another data point. If the errors are correlated, it indicates that there might be a pattern or relationship that the model has not captured, potentially leading to biased estimates.\n",
        "\n",
        "**3. Homoscedasticity (Constant Variance of Errors):**\n",
        "The variance of the errors should be constant across all levels of the independent variable. In other words, the spread (or \"scatter\") of the residuals should remain roughly the same for all values of\n",
        "x.\n",
        "When this assumption is violated, and the error variance changes with the level of the independent variable (i.e., the residuals fan out or contract), it is called heteroscedasticity, which can distort the model's estimates and statistical tests.\n",
        "\n",
        "**4. Normality of Errors:**\n",
        "The residuals (errors) of the model should be approximately normally distributed. This assumption is important for making reliable statistical inferences, such as hypothesis tests and confidence intervals.\n",
        "While this assumption is not crucial for making predictions, it is essential when performing hypothesis testing to determine the significance of the coefficients.\n",
        "\n",
        "**5. No Multicollinearity (for Multiple Linear Regression):**\n",
        "While this assumption is more relevant to Multiple Linear Regression (where there are more than one independent variable), it can also be a concern when extending simple linear regression. It assumes that there is no perfect correlation between the predictors. In Simple Linear Regression, this is not usually a problem since there is only one predictor.\n",
        "\n",
        "**6. No Omitted Variable Bias:**\n",
        "This assumption holds that there are no important variables left out of the model that are correlated with both the independent and dependent variables. If such variables exist but are omitted, the model may provide biased estimates.\n",
        "\n",
        "**7. Measurement Accuracy:**\n",
        "It is assumed that the data (both dependent and independent variables) are measured accurately without significant errors. Measurement errors in the independent variable (x) can lead to attenuation bias (underestimating the slope), while errors in the dependent variable (y) can inflate the residual variance.\n",
        "\n",
        "**Q3:-What does the coefficient m represent in the equation Y=mX+c?**\n",
        "\n",
        "**Ans:-**\n",
        "In the equation of a simple linear regression model: **Y=mX+c**\n",
        "\n",
        "Y is the dependent variable (the output or target you're trying to predict).\n",
        "\n",
        "X is the independent variable (the input or feature used to make predictions).\n",
        "\n",
        "m is the slope (or coefficient) of the line.\n",
        "\n",
        "c is the intercept (the value of Y when X=0).\n",
        "\n",
        "**The coefficient m represent**\n",
        "The coefficient\n",
        "m represents the slope of the line, which tells you how much the dependent variable Y is expected to change for a one-unit change in the independent variable X.\n",
        "\n",
        "In other words:\n",
        "\n",
        "m measures the rate of change of Y as\n",
        "X changes.\n",
        "\n",
        "If m > 0, it indicates a positive relationship between X and Y, meaning as\n",
        "X increases, Y also increases.\n",
        "\n",
        "If ğ‘š < 0, it indicates a negative relationship, meaning as X increases, Y decreases.\n",
        "\n",
        "The magnitude of m tells you how steep the line is. A larger value of m means a steeper slope (i.e., a more significant change in Y for a given change in\n",
        "X).\n",
        "\n",
        "**Q4:-What does the intercept c represent in the equation Y=mX+c?**\n",
        "\n",
        "**Ans:-**\n",
        "In the equation of a simple linear regression model:Y=mX+c\n",
        "\n",
        "Y is the dependent variable (the target or outcome you're predicting).\n",
        "\n",
        "X is the independent variable (the predictor or feature).\n",
        "\n",
        "m is the slope (coefficient) of the line.\n",
        "\n",
        "c is the intercept.\n",
        "\n",
        "**The intercept c represent**\n",
        "\n",
        "The intercept c represents the value of\n",
        "the dependent variable Y when the independent variable X is zero. In other words, it's the point where the regression line crosses the Y-axis.\n",
        "\n",
        "It gives you the predicted value of Y when X=0.\n",
        "\n",
        "In a real-world context, the intercept represents the starting point or baseline value of Y, before any effect from the independent variable X is considered.\n",
        "\n",
        "**Q5:-How do we calculate the slope m in Simple Linear Regression?**\n",
        "\n",
        "**Ans:-**\n",
        "In Simple Linear Regression, the slope\n",
        "m (also known as the coefficient of the independent variable X) is calculated using the least squares method, which minimizes the sum of the squared residuals (the differences between the actual and predicted values).\n",
        "\n",
        "**Q6:-What is the purpose of the least squares method in Simple Linear Regression?**\n",
        "\n",
        "**Ans:-**\n",
        "The least squares method is a core optimization technique used in Simple Linear Regression to find the best-fitting line that minimizes the difference between the actual data points and the predicted values by the model.\n",
        "\n",
        "**Purpose of the Least Squares Method:**\n",
        "\n",
        "The main purpose of the least squares method is to minimize the error between the observed values (Y) and the predicted values (ğ‘Œ^) produced by the regression model.\n",
        "\n",
        "**Q7:- How is the coefficient of determination (RÂ²) interpreted in Simple Linear Regression?**\n",
        "\n",
        "**Ans:-**In Simple Linear Regression, the coefficient of determination (RÂ²) is a key metric used to assess how well the regression model explains the variability of the dependent variable (the target) in relation to the independent variable (the predictor). RÂ² is a value between 0 and 1, and it reflects the proportion of the variance in the dependent variable that is explained by the independent variable.\n",
        "\n",
        "Here's how to interpret RÂ²:\n",
        "\n",
        "RÂ² = 1: A value of 1 indicates that the regression model perfectly explains the variation in the target variable. Every data point lies exactly on the regression line.\n",
        "\n",
        "RÂ² = 0: A value of 0 means the model explains none of the variability in the target. The independent variable has no predictive power in this case.\n",
        "\n",
        "0 < RÂ² < 1: An RÂ² between 0 and 1 indicates that the model explains some, but not all, of the variability in the target variable. The closer RÂ² is to 1, the better the model fits the data.\n",
        "\n",
        "Negative RÂ²: In some cases, particularly when the model fits the data poorly or when a linear regression model is applied to data that is better suited to a different type of model, RÂ² can be negative. This means the model is worse than a horizontal line (the mean of the dependent variable), indicating poor performance.\n",
        "\n",
        "**In Machine Learning:**\n",
        "\n",
        "High RÂ² indicates a good fit, meaning the model captures most of the underlying relationship between the variables.\n",
        "\n",
        "Low RÂ² signals a poor fit, suggesting that the model may not be well-suited to the data or that there are important variables not included in the model.\n",
        "\n",
        "**Limitations:**\n",
        "\n",
        "RÂ² alone doesn't tell you whether the model is appropriate for the data or if the assumptions of linear regression are met.\n",
        "\n",
        "It doesn't account for overfitting. A model may achieve a high RÂ² but may still not generalize well to new data.\n",
        "\n",
        "**Q8:-What is Multiple Linear Regression?**\n",
        "\n",
        "**Ans:-**Multiple Linear Regression (MLR) is an extension of Simple Linear Regression where the relationship between the dependent variable (target) and two or more independent variables (predictors) is modeled. In other words, it is used to predict a target variable based on multiple input features. MLR is widely used in machine learning and statistics for modeling linear relationships when there are multiple features influencing the output.\n",
        "\n",
        "The Model:\n",
        "The equation for Multiple Linear Regression is:\n",
        "\n",
        "ğ‘Œ=ğ›½0+ğ›½1ğ‘‹1+ğ›½2ğ‘‹2+â‹¯+ğ›½ğ‘›ğ‘‹ğ‘›+ğœ–\n",
        "\n",
        "**Where:**\n",
        "\n",
        "Y is the dependent (target) variable.\n",
        "\n",
        "Xâ‚, Xâ‚‚, ..., Xn are the independent (predictor) variables.\n",
        "\n",
        "Î²â‚€ is the intercept of the regression line (the value of Y when all X's are 0).\n",
        "\n",
        "Î²â‚, Î²â‚‚, ..., Î²n are the coefficients that represent the influence of each predictor (X) on the target variable.\n",
        "\n",
        "Îµ is the error term (the difference between the predicted and actual values of Y).\n",
        "\n",
        "**Key Concepts:**\n",
        "**Linear Relationship:** The goal is to find a linear relationship between the target and the predictors, meaning the effect of each independent variable on the dependent variable is additive and proportional.\n",
        "\n",
        "Multiple Features: Unlike simple linear regression, where you use one independent variable to predict the target, multiple linear regression involves more than one predictor. The coefficients (Î²s) quantify how each predictor influences the target, while the intercept accounts for the baseline value of Y.\n",
        "\n",
        "Assumptions: Similar to simple linear regression, multiple linear regression also has a set of assumptions, including:\n",
        "\n",
        "Linearity: The relationship between the target and the predictors is linear.\n",
        "\n",
        "Independence: The residuals (errors) are independent of each other.\n",
        "\n",
        "Homoscedasticity: The variance of the residuals is constant across all levels of the independent variables.\n",
        "\n",
        "Normality of residuals: The residuals should be normally distributed.\n",
        "\n",
        "**Applications in Machine Learning:**\n",
        "\n",
        "Predictive Modeling: MLR is used for predicting continuous variables based on multiple inputs.\n",
        "\n",
        "Feature Selection: It can help identify the most significant predictors.\n",
        "\n",
        "Risk Assessment: In financial and healthcare sectors, for evaluating risks based on multiple factors.\n",
        "\n",
        "**Limitations:**\n",
        "\n",
        "Multicollinearity: When independent variables are highly correlated, it becomes difficult to estimate the individual effect of each predictor.\n",
        "\n",
        "Outliers: MLR is sensitive to outliers, which can distort predictions.\n",
        "\n",
        "Non-linearity: If the relationship between predictors and the target is non-linear, MLR might not provide accurate results.\n",
        "\n",
        "In machine learning, MLR can be a foundation for more complex models, or it can be used as a baseline for comparison with other algorithms.\n",
        "\n",
        "**Q9:-What is the main difference between Simple and Multiple Linear Regression?**\n",
        "\n",
        "**Ans**The main difference between Simple Linear Regression (SLR) and Multiple Linear Regression (MLR) lies in the number of independent variables (predictors) used to model the dependent variable (target):\n",
        "\n",
        "**1. Number of Independent Variables:**\n",
        "\n",
        "**Simple Linear Regression (SLR):**\n",
        "Involves only one independent variable to predict the dependent variable.\n",
        "The relationship is modeled as a straight line.\n",
        "\n",
        "Example equation:\n",
        "ğ‘Œ=ğ›½0+ğ›½1ğ‘‹+ğœ–\n",
        "\n",
        "**Multiple Linear Regression (MLR):**\n",
        "\n",
        "Involves two or more independent variables to predict the dependent variable.\n",
        "The relationship is modeled as a hyperplane (not just a line).\n",
        "\n",
        "Example equation:\n",
        "ğ‘Œ=ğ›½0+ğ›½1ğ‘‹1+ğ›½2ğ‘‹2+â‹¯+ğ›½ğ‘›ğ‘‹ğ‘›+ğœ–\n",
        "\n",
        "**2. Complexity:**\n",
        "\n",
        "**SLR:** Since there's only one predictor, the model is simpler and easier to interpret. Itâ€™s essentially a linear relationship between the target and a single feature.\n",
        "\n",
        "**MLR:** The model becomes more complex as it involves multiple predictors. It has to account for the interactions and individual effects of each predictor on the target.\n",
        "\n",
        "**3. Visualization:**\n",
        "\n",
        "**SLR:** Can be easily visualized in a 2D graph, where the dependent variable is plotted against the independent variable, and the regression line represents the best fit.\n",
        "\n",
        "**MLR:** Can't be easily visualized in 2D since there are multiple predictors. If there are two predictors, it can be plotted in a 3D space. For more than two predictors, it becomes increasingly complex and requires higher-dimensional visualization techniques.\n",
        "\n",
        "**4. Predictive Power:**\n",
        "\n",
        "**SLR:** Limited to using only one predictor to explain the target variable. This can be less effective if there are multiple factors influencing the target.\n",
        "\n",
        "**MLR:** Can use multiple predictors to potentially offer a better fit and more accurate predictions by capturing the relationships between the target and all included features.\n",
        "\n",
        "**5. Model Evaluation:**\n",
        "\n",
        "**SLR:** Evaluation is straightforward, and metrics like RÂ², Mean Squared Error (MSE), and p-values are used to assess model performance.\n",
        "\n",
        "**MLR:** Evaluation includes similar metrics, but it also involves checking for issues like multicollinearity (when predictors are correlated with each other) and possibly adjusting for the number of predictors using Adjusted RÂ² to avoid overfitting.\n",
        "\n",
        "**6. Assumptions:**\n",
        "\n",
        "**SLR:** Assumes a linear relationship between a single predictor and the target, with all the standard regression assumptions (linearity, independence, homoscedasticity, and normality of residuals).\n",
        "\n",
        "**MLR:** Assumes that the relationship between the target and the predictors is linear, but also assumes that the predictors are independent of each other (no multicollinearity). Other assumptions include homoscedasticity and normality of residuals.\n",
        "\n",
        "**Q10:-What are the key assumptions of Multiple Linear Regression?**\n",
        "\n",
        "**Ans:-**The key assumptions of Multiple Linear Regression (MLR) ensure the validity and reliability of the model in explaining the relationship between the dependent variable (target) and the independent variables (predictors). If these assumptions are violated, the model's predictions and inferences may be unreliable.\n",
        "\n",
        "**1. Linearity of Relationships**\n",
        "\n",
        "Assumption: The relationship between the dependent variable (Y) and each independent variable (ğ‘‹ğ‘–) is linear.\n",
        "\n",
        "Implication: The effect of each predictor on the target is additive and proportional.\n",
        "\n",
        "Violation: If the relationship is non-linear, the model will not capture it well, leading to biased predictions.\n",
        "\n",
        "How to Check: Use scatter plots or residual plots. If a curved pattern exists, the assumption may not hold.\n",
        "\n",
        "Solution: Apply transformations (e.g., log, square root) or use non-linear regression methods.\n",
        "\n",
        "**2. Independence of Errors (No Autocorrelation)**\n",
        "\n",
        "Assumption: The residuals (errors) are independent of each other.\n",
        "\n",
        "Implication: There should be no pattern or correlation in the errors; one error should not predict another.\n",
        "\n",
        "Violation: Common in time-series data where residuals are autocorrelated.\n",
        "\n",
        "How to Check: Plot residuals against time or use tests like the Durbin-Watson test.\n",
        "\n",
        "Solution: Consider using models designed for autocorrelated data, such as time-series models (e.g., ARIMA).\n",
        "\n",
        "**3. Homoscedasticity (Constant Variance of Errors)**\n",
        "\n",
        "Assumption: The variance of the residuals is constant across all levels of the independent variables.\n",
        "\n",
        "Implication: The spread of residuals should remain the same regardless of the values of the predictors.\n",
        "\n",
        "Violation: If the variance of residuals increases or decreases (heteroscedasticity), predictions may be less reliable.\n",
        "\n",
        "How to Check: Use residual plots. In homoscedasticity, the residuals should appear randomly scattered with no funnel-shaped patterns.\n",
        "\n",
        "Solution: Apply transformations (e.g., log transformation) or use weighted least squares regression.\n",
        "\n",
        "**4. Normality of Residuals**\n",
        "\n",
        "Assumption: The residuals (errors) should be approximately normally distributed.\n",
        "\n",
        "Implication: This is especially important for making statistical inferences (e.g., confidence intervals, hypothesis testing).\n",
        "\n",
        "Violation: If the residuals are skewed or exhibit heavy tails, the normality assumption is violated.\n",
        "\n",
        "How to Check: Use a Q-Q plot or a histogram of residuals, or perform normality tests like the Shapiro-Wilk test or Kolmogorov-Smirnov test.\n",
        "\n",
        "Solution: Apply transformations to the target variable or consider robust regression techniques.\n",
        "\n",
        "**5. No Multicollinearity**\n",
        "\n",
        "Assumption: The independent variables are not highly correlated with each other.\n",
        "\n",
        "Implication: High multicollinearity makes it difficult to isolate the effect of individual predictors and can lead to unstable coefficient estimates.\n",
        "\n",
        "Violation: When predictors are highly correlated, the regression coefficients may become unreliable, and standard errors increase.\n",
        "\n",
        "How to Check: Use the Variance Inflation Factor (VIF) or correlation matrix. A VIF > 10 indicates severe multicollinearity.\n",
        "\n",
        "Solution: Remove or combine correlated predictors, or use techniques like Principal Component Regression (PCR) or Ridge Regression.\n",
        "\n",
        "**6. Model Specification**\n",
        "\n",
        "Assumption: The model is correctly specified, meaning all relevant variables are included, and irrelevant variables are excluded.\n",
        "\n",
        "Implication: Omitting relevant variables leads to biased coefficients, while including irrelevant ones increases noise.\n",
        "\n",
        "Violation: The model may be under-specified (missing key variables) or over-specified (includes unnecessary predictors).\n",
        "\n",
        "How to Check: Evaluate domain knowledge and use techniques like stepwise regression or cross-validation to refine the model.\n",
        "\n",
        "Solution: Perform feature selection or consult domain expertise.\n",
        "\n",
        "**7. Independent Variable Values are Fixed (Non-Stochastic)**\n",
        "\n",
        "Assumption: The values of the independent variables are fixed or non-random.\n",
        "\n",
        "Implication: This is a theoretical assumption underlying regression but is relaxed in practical applications like machine learning.\n",
        "\n",
        "Violation: If predictors are stochastic (random), results may be less interpretable but are still valid in predictive contexts.\n",
        "\n",
        "**8. Outliers and Influential Points**\n",
        "\n",
        "Assumption: The dataset is free of outliers or influential points that disproportionately affect the regression results.\n",
        "\n",
        "Implication: Outliers can distort the model's coefficients and reduce reliability.\n",
        "\n",
        "Violation: Presence of outliers or high-leverage points can bias predictions and model performance.\n",
        "\n",
        "How to Check: Use diagnostic plots, Cook's distance, or leverage scores.\n",
        "\n",
        "Solution: Remove or transform outliers, or use robust regression techniques.\n",
        "\n",
        "**Q11:-What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?**\n",
        "\n",
        "**Ans:-**\n",
        "Heteroscedasticity occurs when the variance of the residuals (errors) in a regression model is not constant across all levels of the independent variables. In other words, the spread of the residuals changes as the predicted values or independent variables change.In a properly fitted regression model, the residuals should ideally show homoscedasticityâ€”meaning they have a constant variance. Heteroscedasticity violates this assumption and can be observed in a residual plot where the spread of residuals forms a funnel-shaped or uneven pattern.\n",
        "\n",
        "**Causes of Heteroscedasticity**\n",
        "\n",
        "Heteroscedasticity often arises in real-world data due to:\n",
        "\n",
        "Scale Effects: Larger values of the independent variable are associated with larger variability in the dependent variable.\n",
        "\n",
        "Omitted Variables: Excluding important variables from the model can lead to systematic variability in the residuals.\n",
        "\n",
        "Data Characteristics: Certain types of data, such as income, tend to exhibit heteroscedasticity because the variability increases with higher income levels.\n",
        "\n",
        "Model Misspecification: Incorrect model specification, such as assuming a linear relationship when the true relationship is non-linear.\n",
        "Measurement Errors: Unequal measurement errors in different ranges of the data.\n",
        "Effects of Heteroscedasticity on a Multiple Linear Regression Model\n",
        "Heteroscedasticity does not bias the coefficient estimates (ğ›½1,ğ›½2,â€¦,ğ›½ğ‘›Î²1,Î² 2,â€¦,Î² n) of the model, but it affects the reliability and accuracy of the results. Hereâ€™s how it impacts the model:\n",
        "\n",
        "Unreliable Standard Errors:\n",
        " Standard errors of the regression coefficients become inaccurate.\n",
        "This leads to invalid hypothesis tests (e.g., t-tests for individual predictors and F-tests for the overall model significance).\n",
        "\n",
        "Inconsistent p-values:\n",
        "Because standard errors are unreliable, the p-values associated with the coefficients may also be incorrect.\n",
        "\n",
        "This can lead to incorrect conclusions about which predictors are statistically significant.\n",
        "\n",
        "Reduced Model Efficiency:\n",
        "Heteroscedasticity can reduce the efficiency of the ordinary least squares (OLS) estimators, leading to less precise estimates.\n",
        "\n",
        "Distorted Confidence Intervals:\n",
        "Confidence intervals for the coefficients may be too narrow or too wide, leading to misleading interpretations of the model.\n",
        "\n",
        "Impact on Prediction:\n",
        "While heteroscedasticity does not directly affect the predictions of the model, it makes the prediction intervals unreliable because the variance of the residuals is not constant.\n",
        "\n",
        "**Q12:-How can you improve a Multiple Linear Regression model with high multicollinearity?**\n",
        "\n",
        "**Ans:-**\n",
        "When dealing with high multicollinearity in a Multiple Linear Regression model, the coefficients of the predictor variables become unstable and may result in inaccurate predictions or interpretations. Here are strategies to handle this issue:\n",
        "\n",
        "**1. Remove Highly Correlated Predictors**\n",
        "\n",
        "Identify correlations: Use a correlation matrix or Variance Inflation Factor (VIF) to detect multicollinearity among predictors.\n",
        "\n",
        "Remove one of the highly correlated variables: If two or more predictors are strongly correlated, consider removing one of them based on domain knowledge or its contribution to the model.\n",
        "\n",
        "**2. Regularization Techniques**\n",
        "Regularization methods add penalties to the regression to shrink or eliminate coefficients of less important predictors.\n",
        "\n",
        "Ridge Regression: Adds an ğ¿2 penalty term (Î»âˆ‘Î² 2 ) to the loss function, which reduces the impact of multicollinearity without completely removing predictors.\n",
        "\n",
        "Lasso Regression: Adds an ğ¿1penalty term (Î»âˆ‘âˆ£Î²âˆ£), which can shrink some coefficients to zero, effectively performing variable selection.\n",
        "\n",
        "Elastic Net: Combines ğ¿^1and ğ¿^2penalties, balancing the benefits of Ridge and Lasso.\n",
        "\n",
        "**3. Principal Component Regression (PCR)**\n",
        "Dimensionality reduction: Transform the correlated predictors into a smaller set of uncorrelated components using Principal Component Analysis (PCA).\n",
        "Regression on components: Perform regression on the principal components instead of the original predictors.\n",
        "\n",
        "**4. Partial Least Squares Regression (PLS)**\n",
        "Unlike PCA, PLS accounts for the relationship between predictors and the target variable, creating components that maximize variance while considering the target.\n",
        "\n",
        "**5. Collect More Data**\n",
        "Increasing the sample size can reduce the impact of multicollinearity by improving the stability of coefficient estimates.\n",
        "\n",
        "**6. Center and Scale the Data**\n",
        "Standardizing or normalizing predictors can help if the multicollinearity arises due to large differences in the magnitude of variables.\n",
        "\n",
        "**7. Feature Engineering**\n",
        "Combine highly correlated variables into a single feature (e.g., taking averages, ratios, or differences).\n",
        "Use domain knowledge to create features that better explain the target variable.\n",
        "\n",
        "**8. Use a Different Model**\n",
        "Some machine learning models, like decision trees, random forests, or gradient boosting, are not sensitive to multicollinearity and can handle it effectively.\n",
        "\n",
        "**9. Domain Knowledge**\n",
        "Prioritize variables based on their relevance and theoretical importance to the problem. This can guide the selection or elimination of predictors.\n",
        "\n",
        "**10. Diagnostic Tools**\n",
        "After applying any method, check metrics like adjusted ğ‘…^2, VIF, and model performance on validation data to ensure the issue is resolved and the model generalizes well.\n",
        "\n",
        "**Q13:-What are some common techniques for transforming categorical variables for use in regression models?**\n",
        "\n",
        "**Ans:-**\n",
        "Transforming categorical variables into numerical formats is essential for incorporating them into regression models or other machine learning algorithms. Here are some common techniques for transforming categorical variables:\n",
        "\n",
        "**1. One-Hot Encoding**\n",
        "Converts each category into a binary variable (1 or 0).\n",
        "\n",
        "Commonly used when the categorical variable is nominal (no inherent order).\n",
        "\n",
        "**2. Label Encoding**\n",
        "Assigns a unique integer to each category.\n",
        "\n",
        "Commonly used for ordinal variables (categories with a natural order).\n",
        "\n",
        "**3. Binary Encoding**\n",
        "Converts categories into binary code, and each digit of the binary code becomes a new feature.\n",
        "\n",
        "**4. Target Encoding (Mean Encoding)**\n",
        "Replaces each category with the mean of the target variable for that category.\n",
        "\n",
        "**5. Frequency Encoding**\n",
        "Replaces each category with its frequency or count in the dataset.\n",
        "\n",
        "**6. Hash Encoding (Feature Hashing)**\n",
        "Maps categories to integers using a hash function, reducing dimensionality.\n",
        "\n",
        "Useful when the number of categories is very large.\n",
        "\n",
        "**7. Embedding Techniques**\n",
        "Uses neural networks or pre-trained embeddings to create dense,lower-dimensional representations of categories.\n",
        "\n",
        "Often used in deep learning models or NLP tasks.\n",
        "\n",
        "**8. Polynomial Encoding (Orthogonal Encoding)**\n",
        "Converts categorical variables into orthogonal polynomials or spline terms.\n",
        "\n",
        "Useful for capturing complex, non-linear relationships between the categories and the target variable.\n",
        "\n",
        "**9. Dummy Encoding**\n",
        "Similar to one-hot encoding but drops one of the categories (the reference category) to avoid multicollinearity in linear models.\n",
        "\n",
        "**10. Custom Encoding**\n",
        "Tailored to specific domains or datasets, applying manual rules to convert categories into numerical values based on domain knowledge.\n",
        "\n",
        "**Q14:-What is the role of interaction terms in Multiple Linear Regression?**\n",
        "\n",
        "**Ans:-**\n",
        "In Multiple Linear Regression, interaction terms allow the model to account for situations where the effect of one predictor variable on the target variable depends on the value of another predictor. These terms help capture more complex relationships between variables that cannot be modeled with simple additive effects alone. Here's a deeper dive into their role:\n",
        "\n",
        "**1. Capturing Non-Additive Effects**\n",
        "In a standard linear regression model, the effect of each predictor is assumed to be independent and additive:\n",
        "ğ‘Œ=ğ›½0+ğ›½1ğ‘‹1+ğ›½2ğ‘‹2+ğœ–\n",
        "\n",
        "Interaction terms account for cases where the combined effect of ğ‘‹1and ğ‘‹2is not simply the sum of their individual effects:\n",
        "ğ‘Œ=ğ›½0+ğ›½1ğ‘‹1+ğ›½2ğ‘‹2+ğ›½3(ğ‘‹1â‹…ğ‘‹2)+ğœ–\n",
        "Here, Î² 3  quantifies the interaction effect between ğ‘‹1and ğ‘‹2.\n",
        "\n",
        "**2. Enhancing Predictive Power**\n",
        "\n",
        "Interaction terms improve the flexibility of the model by enabling it to capture more intricate patterns in the data.\n",
        "They are particularly useful when predictors exhibit combined effects that are not linear or additive.\n",
        "\n",
        "**3. Interpreting Interaction Effects**\n",
        "The coefficient of an interaction term (ğ›½3) indicates how the relationship between one predictor and the target changes depending on the level of the other predictor.\n",
        "\n",
        "**4. Identifying Complex Relationships**\n",
        "Interaction terms reveal dependencies that might not be obvious in the raw data.\n",
        "For example, if the effect of a marketing campaign (predictor) depends on the region where it was implemented (another predictor), an interaction term between these variables would capture that relationship.\n",
        "\n",
        "**5. Testing Hypotheses**\n",
        "Interaction terms can test specific hypotheses about relationships between variables.\n",
        "For example, in an A/B test scenario, an interaction term between \"group\" (A/B) and \"age\" can test whether the effect of being in group A vs. group B depends on the age of the participant.\n",
        "\n",
        "**6. Challenges of Using Interaction Terms**\n",
        "\n",
        "Multicollinearity: Interaction terms can introduce multicollinearity, particularly if the original predictors are correlated. Centering or standardizing the predictors can help mitigate this.\n",
        "\n",
        "Overfitting: Including too many interaction terms, especially in models with limited data, can lead to overfitting. Regularization techniques like Ridge or Lasso regression can help.\n",
        "\n",
        "Interpretation Complexity: As the number of interaction terms increases, the model becomes harder to interpret.\n",
        "\n",
        "**7. When to Use Interaction Terms**\n",
        "\n",
        "Domain Knowledge: When you suspect or know that two variables interact in influencing the target.\n",
        "\n",
        "Exploratory Data Analysis: Observing non-linear or conditional relationships between predictors and the target variable.\n",
        "\n",
        "Feature Engineering: Interaction terms are often a key part of creating meaningful features for machine learning models.\n",
        "\n",
        "**8. Interaction Terms in Practice**\n",
        "Categorical Variables: Interaction terms between categorical variables or between a categorical and a continuous variable can represent conditional relationships.\n",
        "\n",
        "**Q15How can the interpretation of intercept differ between Simple and Multiple Linear Regression?**\n",
        "\n",
        "**Ans:-**\n",
        "The interpretation of the intercept differs between Simple Linear Regression and Multiple Linear Regression due to the number of predictors and how they influence the model. Hereâ€™s a breakdown:\n",
        "\n",
        "**1. Simple Linear Regression**\n",
        "The model has one predictor:ğ‘Œ=ğ›½0+ğ›½1ğ‘‹+ğœ–\n",
        "\n",
        "Intercept (ğ›½0) meaning:\n",
        "\n",
        "It is the expected value of Y when X=0.\n",
        "\n",
        "In practical terms, it represents the starting point or baseline value of the target variable when the predictor is zero.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "If Y is the price of a house and X is the size of the house (in square feet:\n",
        "\n",
        "ğ›½0: The expected price of a house when its size is 0 square feet.\n",
        "\n",
        "**Important Notes:**\n",
        "\n",
        "The intercept can be meaningful or not, depending on whether X=0 makes sense in the context. For instance, a house with 0 square feet may not be realistic, making Î² 0 purely a mathematical artifact.\n",
        "\n",
        "**2. Multiple Linear Regression**\n",
        "\n",
        "The model has multiple predictors:\n",
        "Y=Î² 0â€‹+Î² 1X 1+Î² 2X 2â€‹+â‹¯+Î² nâ€‹X nâ€‹+Ïµ\n",
        "\n",
        "**Intercept (ğ›½0) meaning:**\n",
        "\n",
        "It is the expected value of Y when all predictors (X 1,X 2,...,X n) are equal to 0.\n",
        "\n",
        "It represents the baseline value of the target variable, assuming that all predictors have no influence (i.e., they are zero).\n",
        "\n",
        "**Example:**\n",
        "\n",
        "Suppose ğ‘Œis salary, ğ‘‹1is years of experience, and ğ‘‹2is education level:ğ›½0: The expected salary for someone with 0 years of experience and 0 education level (assuming those values are possible).\n",
        "\n",
        "**Key Difference from Simple Linear Regression:**\n",
        "\n",
        "In multiple regression, the interpretation of the intercept depends on all predictors being 0 simultaneously, which may or may not make sense in the context. For instance:\n",
        "\n",
        "If one of the predictors is categorical (e.g., gender), X=0 might represent a specific category.\n",
        "\n",
        "If predictors are standardized or centered, X=0 often represents the mean values of those predictors, making the intercept more interpretable.\n",
        "\n",
        "**Q16:-What is the significance of the slope in regression analysis, and how does it affect predictions?**\n",
        "\n",
        "**Ans:-**\n",
        "In regression analysis, particularly in the context of machine learning, the slope represents the relationship between the independent variable (feature) and the dependent variable (target). Its significance lies in how it quantifies the effect of a one-unit change in the feature on the predicted outcome.\n",
        "\n",
        "**Key Points About the Slope:**\n",
        "\n",
        "**Definition:**\n",
        "\n",
        "For a simple linear regression model, the equation is typically written as:\n",
        "y=mx+b\n",
        "\n",
        "**Here:**\n",
        "ğ‘š (the slope) indicates how much ğ‘¦ changes when ğ‘¥ increases by one unit.\n",
        "ğ‘ (the intercept) is the value of ğ‘¦ when ğ‘¥ is 0.\n",
        "\n",
        "**Direction of the Relationship:**\n",
        "\n",
        "**Positive Slope:** A positive value means there is a direct relationship between ğ‘¥ and ğ‘¦. As ğ‘¥ increases, ğ‘¦ also increases.\n",
        "\n",
        "**Negative Slope:** A negative value indicates an inverse relationship. As ğ‘¥ increases, ğ‘¦ decreases.\n",
        "\n",
        "**Zero Slope:** If the slope is 0, ğ‘¦is unaffected by changes in ğ‘¥(no relationship).\n",
        "\n",
        "**Magnitude:**\n",
        "\n",
        "The magnitude of the slope reflects the strength of the effect. A larger absolute value of the slope means that changes in ğ‘¥ have a stronger influence on ğ‘¦.\n",
        "For example, if ğ‘š=5, a one-unit increase in ğ‘¥ leads to a five-unit increase in ğ‘¦.\n",
        "\n",
        "**Multiple Regression:**\n",
        "\n",
        "In multiple linear regression, where the model is:ğ‘¦=ğ›½0+ğ›½1ğ‘¥1+ğ›½2ğ‘¥2+â‹¯+ğ›½ğ‘›ğ‘¥ğ‘› Each slope (ğ›½ğ‘–) represents the effect of a specific feature ğ‘¥ğ‘– on y, assuming all other features are held constant.\n",
        "\n",
        "**How the Slope Affects Predictions:**\n",
        "\n",
        "**Direct Impact on Model Outputs:** The slope determines the weight of a feature in the prediction. A high slope means that feature has a significant influence on the target variable.\n",
        "\n",
        "**Interpretability:** In explainable machine learning models, slopes help in understanding which features are most important and how they affect the outcome.\n",
        "\n",
        "**Optimization:** During training, algorithms adjust slopes (weights in the case of linear regression) to minimize prediction errors (e.g., using gradient descent).\n",
        "\n",
        "**Practical Considerations:**\n",
        "\n",
        "**Feature Scaling:** If features are not normalized, the slope may be misleading because it depends on the scale of the feature.\n",
        "\n",
        "**Correlation:** A high slope might indicate strong correlation, but it does not imply causation. Other factors or confounding variables may influence the outcome.\n",
        "\n",
        "**Q17:-How does the intercept in a regression model provide context for the relationship between variables?**\n",
        "\n",
        "**Ans:-**\n",
        "In a regression model, the intercept plays a crucial role in providing context for the relationship between variables. It represents the expected value of the dependent variable (y) when all independent variables (x) are equal to zero. Here's a detailed breakdown of its significance and role, particularly in the context of machine learning:\n",
        "\n",
        "**Definition of the Intercept**\n",
        "\n",
        "**In the regression equation:**\n",
        "\n",
        "       y=mx+b  (forÂ simpleÂ linearÂ regression)\n",
        "or\n",
        "\n",
        "ğ‘¦=ğ›½0+ğ›½1ğ‘¥1+ğ›½2ğ‘¥2+â‹¯+ğ›½ğ‘›ğ‘¥ğ‘›(forÂ multipleÂ linearÂ regression),\n",
        "\n",
        "the intercept (b or ğ›½0) is the value of y when all the independent variables (ğ‘¥1,ğ‘¥2,â€¦,ğ‘¥ğ‘›) are zero.\n",
        "\n",
        "**Context Provided by the Intercept**\n",
        "\n",
        "**Baseline Value:**\n",
        "\n",
        "The intercept gives a baseline prediction for the dependent variable when no predictors are influencing it (i.e., when x=0).\n",
        "Example: In a model predicting housing prices, the intercept might represent the average price of a house with no features (e.g., 0 bedrooms, 0 bathrooms, etc.). While not always realistic, it provides a reference point.\n",
        "\n",
        "**Starting Point in the Model:**\n",
        "\n",
        "The intercept sets the foundation for the model's predictions. It anchors the regression line or plane in the data space.\n",
        "\n",
        "**Context for Feature Effects:**\n",
        "\n",
        "By itself, the intercept may not hold meaningful information if x=0 is outside the range of observed data (e.g., negative income or age values).\n",
        "However, combined with slopes, it ensures that the predicted values align with the relationships captured during training.\n",
        "\n",
        "**Interpretability:**\n",
        "\n",
        "In machine learning, the intercept can indicate the default or average behavior of the target variable when the features have minimal or no contribution.\n",
        "For categorical variables encoded numerically (e.g., one-hot encoding), the intercept often represents the baseline category.\n",
        "Importance in Machine Learning\n",
        "\n",
        "**Bias Term in Models:**\n",
        "\n",
        "In machine learning, the intercept is equivalent to the bias term. It shifts the prediction output up or down to minimize errors and better fit the training data.\n",
        "Without the intercept, the regression line/plane would always pass through the origin, which could lead to poor model performance.\n",
        "\n",
        "**Adjusting for Feature Interactions:**\n",
        "\n",
        "When multiple features interact in non-obvious ways, the intercept accounts for the \"average\" effect when features are zeroed out.\n",
        "\n",
        "**Scaling and Normalization:**\n",
        "\n",
        "If features are scaled or normalized, the intercept may change, as the range of\n",
        "x and the meaning of x=0 changes. This does not affect the relationship between variables but adjusts the baseline prediction accordingly.\n",
        "\n",
        "**Q18:-What are the limitations of using RÂ² as a sole measure of model performance?**\n",
        "\n",
        "**ANS:-**\n",
        "Using ğ‘…2(coefficient of determination) as the sole measure of model performance in machine learning has several limitations. While ğ‘…2provides insights into how well the model explains the variability in the target variable, relying on it exclusively can lead to misleading conclusions about the model's quality and generalizability.\n",
        "\n",
        "**Limitations of ğ‘…2:**\n",
        "\n",
        "**Does Not Measure Predictive Performance:**\n",
        "ğ‘…2quantifies the proportion of variance in the target variable explained by the model. However, it does not directly measure how well the model predicts unseen data.\n",
        "\n",
        "A high ğ‘…2on the training data does not guarantee good performance on the test data or real-world scenarios (overfitting risk).\n",
        "\n",
        "**Insensitive to Overfitting:**\n",
        "A complex model can achieve a very high ğ‘…2on the training dataset by overfitting (capturing noise in addition to the signal), but this does not indicate good generalization.\n",
        "\n",
        "**Not Useful for Non-Linear Models:**\n",
        "ğ‘…2is commonly associated with linear regression and may not accurately reflect the performance of non-linear or complex models like decision trees, neural networks, or support vector machines.\n",
        "\n",
        "**Cannot Handle Nonlinear Relationships Alone:**\n",
        "If the relationship between features and the target variable is non-linear, ğ‘…2might suggest a poor fit even if the model captures the pattern well.\n",
        "\n",
        "**Misleading with High-Dimensional Data:**\n",
        "In high-dimensional datasets (many features), adding more features will often increase ğ‘…2regardless of whether they are meaningful or improve the model. This is particularly problematic in cases of over-parameterization.\n",
        "\n",
        "**Insensitive to Bias and Variance:**\n",
        "ğ‘…2does not distinguish between bias (systematic error) and variance (sensitivity to data fluctuations), both of which are critical for understanding model behavior.\n",
        "\n",
        "**Does Not Account for Model Complexity:**\n",
        "ğ‘…2does not penalize models for unnecessary complexity, which can lead to overfitting. Alternative metrics like adjusted ğ‘…2or Akaike Information Criterion (AIC) are more suitable when considering model complexity.\n",
        "\n",
        "**Limited Interpretability with Certain Data:**\n",
        "If the target variable has a low variance, even a high ğ‘…2may not mean the model is useful because it explains a small amount of variability in absolute terms.\n",
        "\n",
        "Conversely, if the variance is high, a low ğ‘…2may still correspond to reasonable predictions.\n",
        "\n",
        "**Scale Dependency:**ğ‘…2assumes the variance of the target variable is a meaningful benchmark. In some cases (e.g., imbalanced datasets or skewed distributions), this assumption may not hold.\n",
        "\n",
        "**Does Not Reflect Error Magnitude:**\n",
        "ğ‘…2does not provide information about the magnitude of prediction errors. For example, a model with a high ğ‘…2could still have large mean absolute errors (MAE) or root mean squared errors (RMSE), making it unsuitable for tasks where precise predictions are critical.\n",
        "\n",
        "**Q19:-How would you interpret a large standard error for a regression coefficient?**\n",
        "\n",
        "**Ans:-**\n",
        "A large standard error for a regression coefficient in a machine learning regression model suggests low confidence in the estimated value of that coefficient. It indicates that the coefficient is highly variable and that the data does not strongly support a specific value for it. Here's a detailed interpretation of what a large standard error might imply\n",
        "\n",
        "**Implications of a Large Standard Error:**\n",
        "\n",
        "**Uncertainty in the Coefficient Estimate:**\n",
        "A large standard error means the estimate of the coefficient (ğ›½) is imprecise. Small changes in the data could lead to significant changes in the value of the coefficient during training.\n",
        "\n",
        "**Weak Relationship Between the Feature and the Target:**\n",
        "It could indicate that the corresponding independent variable (feature) has little or no impact on the target variable. In other words, the data does not provide strong evidence that this feature is predictive of the outcome.\n",
        "\n",
        "**Multicollinearity:**\n",
        "If the model includes multiple features that are highly correlated with each other (multicollinearity), it becomes difficult to isolate the effect of individual features. This can inflate the standard errors of the regression coefficients, even if the overall model performance is reasonable.\n",
        "\n",
        "**Insufficient or Poor-Quality Data:**\n",
        "A small sample size or noisy data can lead to large standard errors. This is because the model does not have enough consistent information to reliably estimate the coefficient.\n",
        "\n",
        "**Feature Scaling Issues:**\n",
        "Features with different scales or units can sometimes lead to large standard errors, especially if the features are not standardized. In such cases, the interpretation of the coefficients and their standard errors becomes challenging.\n",
        "\n",
        "**Overfitting or Redundant Features:**\n",
        "Including irrelevant or redundant features in the model can cause large standard errors for some coefficients. This happens because the model tries to assign weights to features that do not significantly contribute to predictions.\n",
        "\n",
        "**Interpreting a Large Standard Error :**\n",
        "\n",
        "**Statistical Significance:**The t-statistic for a regression coefficient is calculated as:\n",
        "\n",
        "t= StandardÂ Error/CoefficientÂ Estimate\n",
        "\n",
        "A large standard error reduces the t-statistic, making it less likely that the coefficient is statistically significant (p-value > 0.05). This suggests the feature might not be important for predicting the target.\n",
        "\n",
        "**Practical Example:**\n",
        "\n",
        "Suppose you're predicting house prices based on features like square footage, number of bedrooms, and proximity to a park. If the coefficient for \"proximity to a park\" has a large standard error, it might mean:\n",
        "\n",
        "The effect of proximity on house prices is not well-supported by the data (e.g., the data lacks sufficient variation in proximity).\n",
        "\n",
        "There could be collinearity between \"proximity to a park\" and other features, like neighborhood or location.\n",
        "\n",
        "**Q20:-How can heteroscedasticity be identified in residual plots, and why is it important to address it?**\n",
        "\n",
        "**Ans:-**\n",
        "\n",
        "Identifying Heteroscedasticity in Residual Plots\n",
        "Heteroscedasticity occurs when the variance of the residuals (errors) is not constant across all levels of the independent variable(s) in a regression model. It violates a key assumption of ordinary least squares (OLS) regression, which assumes homoscedasticity (constant variance). Here's how to identify\n",
        "\n",
        "**heteroscedasticity in residual plots:**\n",
        "\n",
        "**Steps to Identify Heteroscedasticity:**\n",
        "\n",
        "**Residual vs. Predicted Values Plot:**\n",
        "Plot the residuals (actualâˆ’predicted) on the y-axis against the predicted values or one of the independent variables on the x-axis.\n",
        "\n",
        "**Heteroscedasticity** is visible when:\n",
        "\n",
        "Residuals form a funnel shape (narrower at some parts, wider at others).\n",
        "\n",
        "Residuals systematically increase or decrease in spread with changes in predicted values or an independent variable.\n",
        "\n",
        "**Patterns to Look For:**\n",
        "\n",
        "**Fan or Cone Shape:** Residuals spread out as the predicted values increase or decrease, indicating non-constant variance.\n",
        "\n",
        "**Clusters or Gaps:** Certain ranges of the predicted values may show higher residual variance than others.\n",
        "\n",
        "**Quantitative Tests:**\n",
        "Perform formal tests for heteroscedasticity:\n",
        "\n",
        "**Breusch-Pagan Test:** Assesses whether residual variance is dependent on the independent variables.\n",
        "\n",
        "**White Test:** A more general test for heteroscedasticity, useful for detecting nonlinear patterns.\n",
        "\n",
        "These tests output a p-value; a small p-value (e.g., < 0.05) suggests heteroscedasticity.\n",
        "\n",
        "**Q-Q Plot of Residuals:**\n",
        "\n",
        "While primarily used to assess normality, any deviations from expected patterns in the spread of residuals can hint at heteroscedasticity.\n",
        "\n",
        "**Why Addressing Heteroscedasticity Is Important**\\\n",
        "\n",
        "**Biased Standard Errors:**\n",
        "Heteroscedasticity leads to incorrect estimates of the standard errors of the regression coefficients.\n",
        "This can affect hypothesis testing, leading to misleading t-statistics and p-values, and resulting in incorrect conclusions about feature significance.\n",
        "\n",
        "**Inefficiency of Coefficient Estimates:**\n",
        "While the regression coefficients themselves remain unbiased, heteroscedasticity makes them less efficient (higher variance). This can reduce the reliability of the model.\n",
        "\n",
        "**Poor Predictions:**\n",
        "A model with heteroscedastic errors might perform poorly in real-world predictions, particularly in regions of the data where error variance is higher.\n",
        "\n",
        "**Violation of OLS Assumptions:**\n",
        "Many statistical and machine learning algorithms, particularly those based on OLS, assume homoscedasticity. Violation of this assumption can compromise the model's validity and interpretability.\n",
        "\n",
        "**Undermines Confidence Intervals:**\n",
        "Heteroscedasticity affects the calculation of confidence intervals, making them unreliable.\n",
        "\n",
        "**How to Address Heteroscedasticity**\n",
        "\n",
        "**Transform the Target Variable:**\n",
        "\n",
        "Apply transformations to the dependent variable (y) to stabilize variance:\n",
        "\n",
        "**Log Transformation:** Use log(y) if residual variance increases with y.\n",
        "\n",
        "**Square Root Transformation:** Use ğ‘¦for moderate heteroscedasticity.\n",
        "\n",
        "**Box-Cox Transformation:** Identifies an optimal power transformation to stabilize variance.\n",
        "\n",
        "**Use Weighted Least Squares (WLS):**\n",
        "Assign weights to observations inversely proportional to their variance. Observations with higher variance are given less weight in the regression.\n",
        "\n",
        "**Apply Robust Regression:**\n",
        "Use regression techniques robust to heteroscedasticity (e.g., Huber regression or quantile regression).\n",
        "\n",
        "**Use Heteroscedasticity-Robust Standard Errors:**\n",
        "Adjust standard errors to account for non-constant variance. Examples include:\n",
        "Huber-White Standard Errors (also called robust standard errors).\n",
        "\n",
        "**Redefine or Add Features:**\n",
        "If heteroscedasticity arises due to omitted variable bias, identify and include relevant features to improve the model.\n",
        "\n",
        "**Segment the Data:**\n",
        "If heteroscedasticity is localized to specific regions of the data, consider creating separate models for those regions.\n",
        "\n",
        "**Practical Example**\n",
        "\n",
        "**Residual Plot Analysis:**\n",
        "Imagine you're predicting house prices based on square footage, and your residual plot shows a cone-shaped pattern:\n",
        "\n",
        "**Cause:** Houses with larger square footage might have more unpredictable pricing due to other factors (e.g., luxury features, location).\n",
        "\n",
        "**Solution:** Transform the target variable (e.g., log-transform house prices) or apply WLS.\n",
        "\n",
        "**Q21:-What does it mean if a Multiple Linear Regression model has a high RÂ² but low adjusted RÂ²?**\n",
        "\n",
        "**Ans:-**\n",
        "If a Multiple Linear Regression model has a high ğ‘…2but a low adjusted ğ‘…2, it usually indicates issues with the model, specifically relating to the inclusion of irrelevant or redundant features. Hereâ€™s what this situation means in the context of machine learning:\n",
        "\n",
        "**#Interpretation**\n",
        "\n",
        "**#High ğ‘…2**:ğ‘…2measures the proportion of the variance in the dependent variable (target) that is explained by the independent variables (features). A high ğ‘…2suggests that the model explains a large portion of the variability in the data.\n",
        "**#Low Adjusted ğ‘…2:**\n",
        "Adjusted ğ‘…2modifies ğ‘…2to account for the number of features in the model. It penalizes the addition of irrelevant features that do not contribute meaningfully to explaining the target variable.\n",
        "\n",
        "A low adjusted ğ‘…2 relative to ğ‘…2means that many of the added features are not improving the model and may be introducing noise.\n",
        "\n",
        "**Possible Causes**\n",
        "\n",
        "**Inclusion of Irrelevant Features:**\n",
        "Irrelevant or non-informative features inflate ğ‘…2because they add complexity, but they do not improve the modelâ€™s predictive power. Adjusted ğ‘…2penalizes for this, leading to a lower value.\n",
        "\n",
        "**Overfitting:**\n",
        "The model may be overfitting the training data by capturing noise or randomness as patterns. This results in a high ğ‘…2, but adjusted ğ‘…2flags this issue by reflecting the true usefulness of features.\n",
        "\n",
        "**High Dimensionality:**\n",
        "When the number of features is close to or exceeds the number of observations,ğ‘…2tends to increase because more features can fit the data better, but adjustedğ‘…2accounts for this and decreases.\n",
        "\n",
        "**Multicollinearity:**\n",
        "Highly correlated features (multicollinearity) can artificially inflate ğ‘…2, but adjusted ğ‘…2penalizes the redundancy.\n",
        "\n",
        "**#Implications in Machine Learning**\n",
        "\n",
        "**Model Complexity:** A high ğ‘…2but low adjusted ğ‘…2suggests the model is unnecessarily complex and may generalize poorly to unseen data.\n",
        "\n",
        "**Feature Engineering:** Many of the features in the model may be irrelevant or redundant, requiring feature selection or engineering to simplify the model.\n",
        "How to Address This Issue\n",
        "\n",
        "**Feature Selection:**\n",
        "Use techniques like Recursive Feature Elimination (RFE), Lasso Regression (L1 regularization), or Feature Importance Scores to identify and remove irrelevant features.\n",
        "\n",
        "**Regularization:**\n",
        "Apply regularization techniques like Ridge Regression (L2 regularization) or Elastic Net to prevent overfitting and reduce the impact of irrelevant features.\n",
        "\n",
        "**Cross-Validation:**\n",
        "Evaluate the model using cross-validation to ensure it generalizes well and does not rely on spurious patterns.\n",
        "\n",
        "**Dimensionality Reduction:**\n",
        "Use methods like Principal Component Analysis (PCA) or t-SNE to reduce the number of features while retaining most of the variance in the data.\n",
        "\n",
        "**Check Multicollinearity:**\n",
        "Use the Variance Inflation Factor (VIF) to detect multicollinearity among features. If multicollinearity exists, consider removing or combining correlated features.\n",
        "\n",
        "**Simplify the Model:**\n",
        "Reevaluate the necessity of all features and consider using only the most relevant ones. A simpler model often generalizes better and has a higher adjusted ğ‘…2 .\n",
        "\n",
        "**#Example**\n",
        "Suppose youâ€™re building a model to predict house prices using features like square footage, number of bedrooms, year built, proximity to schools, and random, non-informative features like a unique identifier (e.g., \"House ID\").\n",
        "\n",
        "**High ğ‘…2:** The model fits well because it includes all features, even irrelevant ones like \"House ID.\"\n",
        "\n",
        "**Low Adjusted ğ‘…2:** Adjusted ğ‘…2reveals that the irrelevant features are not improving the modelâ€™s true predictive power and are being penalized.\n",
        "By removing irrelevant features like \"House ID\" and retraining the model, you may see adjusted ğ‘…2increase, signaling a better model\n",
        "\n",
        "**Q22:-Why is it important to scale variables in Multiple Linear Regression?**\n",
        "\n",
        "**Ans:-**\n",
        "caling variables in Multiple Linear Regression is important, particularly in the context of machine learning, for several reasons:\n",
        "\n",
        "**1. To Handle Disparity in Feature Magnitudes**\n",
        "When variables have vastly different scales (e.g., one feature is measured in thousands and another in fractions), their coefficients are affected disproportionately during optimization.\n",
        "\n",
        "**Example:** If one feature represents \"income in dollars\" (ranging from\n",
        "30,000 to100,000) and another represents \"years of experience\" (ranging from 0 to 30), the large magnitude of income may dominate the regression computation, making the model less sensitive to smaller-scale features.\n",
        "\n",
        "**2. To Improve Numerical Stability**\n",
        "Regression algorithms involve matrix operations (e.g., inversion of the design matrix) that can become numerically unstable when variables have drastically different scales.\n",
        "\n",
        "Scaling ensures that the optimization process is more stable and prevents potential issues like exploding or vanishing gradients during training.\n",
        "\n",
        "**3. For Faster Convergence**\n",
        "Gradient descent-based optimization, used in many regression models and machine learning algorithms, benefits from scaling.\n",
        "\n",
        "Features with different scales result in gradients that vary significantly, slowing convergence. Scaling ensures a more uniform contribution from all features, speeding up the optimization process.\n",
        "\n",
        "**4. To Interpret Coefficients Accurately**\n",
        "Without scaling, the regression coefficients are influenced by the magnitude of the features. This can make interpretation of coefficients difficult or misleading because larger-scale features will naturally have larger coefficients.\n",
        "\n",
        "**Example:** A coefficient for income in \"thousands of dollars\" would be much smaller than a coefficient for \"number of bedrooms,\" but this difference would not necessarily reflect their relative importance in predicting the target variable.\n",
        "\n",
        "**5. When Using Regularization**\n",
        "If the regression model incorporates regularization techniques like Ridge (L2 regularization) or Lasso (L1 regularization), scaling is critical.\n",
        "\n",
        "Regularization penalizes large coefficients, and the penalty is directly influenced by the scale of the features. Without scaling, the penalty would disproportionately affect features with smaller magnitudes, leading to biased results.\n",
        "\n",
        "**6. When Working with Distance-Based Models**\n",
        "Even though scaling is not inherently required for standard Multiple Linear Regression, it becomes critical when the regression model is part of a pipeline that includes algorithms like k-Nearest Neighbors, Support Vector Machines, or clustering, which are sensitive to feature magnitudes.\n",
        "\n",
        "**Q23:-What is polynomial regression?**\n",
        "\n",
        "**Ans:-**\n",
        "What is Polynomial Regression?\n",
        "Polynomial Regression is a type of regression analysis where the relationship between the independent variable(s) (features) and the dependent variable (target) is modeled as a polynomial equation. Unlike simple linear regression, which fits a straight line to the data, polynomial regression can fit a non-linear curve, allowing it to capture more complex relationships.\n",
        "\n",
        "Key Features of Polynomial Regression\n",
        "\n",
        "**1.Model Equation:**\n",
        "For a single feature (\n",
        "ğ‘¥\n",
        "x), the polynomial regression model is expressed as:\n",
        "ğ‘¦=ğ›½0+ğ›½1ğ‘¥+ğ›½2ğ‘¥2+ğ›½3ğ‘¥3+â‹¯+ğ›½ğ‘›ğ‘¥ğ‘›+ğœ–\n",
        "\n",
        "Î²0,Î²1â€‹,â€¦,Î² n: Coefficients of the polynomial terms.\n",
        "\n",
        "ğ‘¥^ğ‘›: Higher-order terms of the independent variable.\n",
        "\n",
        "ğœ–: Error term (unexplained variability).\n",
        "\n",
        "**2.Degree of the Polynomial:**\n",
        "\n",
        "The degree of the polynomial (ğ‘›) determines the flexibility of the model. For example:\n",
        "\n",
        "n=1: Linear regression (straight line).\n",
        "\n",
        "n=2: Quadratic regression (parabolic curve).\n",
        "\n",
        "n=3: Cubic regression (more flexible curve).\n",
        "\n",
        "**3.Non-Linear Relationship:**\n",
        "\n",
        "Although the relationship between ğ‘¥and ğ‘¦is non-linear, polynomial regression is still a linear model in the sense that it is linear with respect to the coefficients (\n",
        "ğ›½0,ğ›½1,â€¦,ğ›½ğ‘›).\n",
        "\n",
        "**4.Extension to Multiple Features:**\n",
        "Polynomial regression can be extended to handle multiple features by including interaction terms and higher-degree terms for each feature.\n",
        "\n",
        "**Q24:-How does polynomial regression differ from linear regression?**\n",
        "\n",
        "**Ans:-**\n",
        "Differences Between Polynomial Regression and Linear Regression in Machine Learning\n",
        "Both linear regression and polynomial regression are regression techniques, but they differ in how they model the relationship between the independent variable(s) (features) and the dependent variable (target). Here's a detailed comparison:\n",
        "\n",
        "**1. Relationship Between Variables**\n",
        "\n",
        "**Linear Regression:**\n",
        "\n",
        "Models a linear relationship between the independent variable(s) and the dependent variable.\n",
        "The equation of the model is:y=Î²0â€‹+Î²1x+Ïµ\n",
        "where:\n",
        "\n",
        "ğ›½0: Intercept\n",
        "\n",
        "ğ›½1: Slope (linear coefficient)\n",
        "\n",
        "ğ‘¥: Independent variable\n",
        "\n",
        "ğœ–: Error term\n",
        "\n",
        "**Polynomial Regression:**\n",
        "\n",
        "Models a non-linear relationship by including higher-order polynomial terms of the independent variable(s).\n",
        "\n",
        "The equation is:y=Î² 0+Î² 1x+Î² 2â€‹x 2+Î² 3â€‹x 3+â‹¯+Î² nâ€‹x n+Ïµ\n",
        "\n",
        "Here, x^2,x^3,â€¦,x^n are higher-order terms that allow the model to fit curves instead of straight lines.\n",
        "\n",
        "**2. Model Flexibility**\n",
        "\n",
        "**Linear Regression:**\n",
        "Can only fit a straight line to the data.\n",
        "Limited to capturing simple relationships where the target changes linearly with features.\n",
        "\n",
        "**Polynomial Regression:**\n",
        "Can fit more complex, non-linear curves to the data by adjusting the degree of the polynomial.\n",
        "Higher degrees allow the model to capture intricate patterns but increase the risk of overfitting.\n",
        "\n",
        "**3. Feature Engineering**\n",
        "\n",
        "**Linear Regression:**\n",
        "Directly uses the features as they are without transforming them.\n",
        "\n",
        "**Polynomial Regression:**\n",
        "Involves transforming the features into polynomial terms.\n",
        "\n",
        "**4. Complexity and Interpretability**\n",
        "\n",
        "**Linear Regression:**\n",
        "Simple and easy to interpret because each coefficient represents the change in the target variable for a one-unit change in the feature.\n",
        "Works well for datasets with a linear relationship.\n",
        "\n",
        "**Polynomial Regression:**\n",
        "More complex and harder to interpret, especially as the degree of the polynomial increases.\n",
        "Higher-order terms make it challenging to explain the impact of individual features on the target variable.\n",
        "\n",
        "**5. Overfitting and Underfitting**\n",
        "\n",
        "**Linear Regression:**\n",
        "Prone to underfitting if the relationship between variables is non-linear, as it cannot capture the underlying patterns in such cases.\n",
        "\n",
        "**Polynomial Regression:**\n",
        "More prone to overfitting, especially when the degree of the polynomial is too high, as it can fit the noise in the data rather than the actual pattern.\n",
        "Needs techniques like cross-validation or regularization to balance complexity.\n",
        "\n",
        "**6. Performance**\n",
        "\n",
        "**Linear Regression:**\n",
        "Works well for simple, linear relationships.\n",
        "Faster to train and computationally less expensive.\n",
        "\n",
        "**Polynomial Regression:**\n",
        "More powerful for non-linear relationships.\n",
        "Can be computationally expensive if the polynomial degree is very high or the dataset is large.\n",
        "\n",
        "**7. Visual Representation**\n",
        "\n",
        "**Linear Regression:**\n",
        "Fits a straight line:\n",
        "\n",
        "**Polynomial Regression:**\n",
        "Fits a curve that can bend based on the degree of the polynomial:\n",
        "\n",
        "**8. Use Cases**\n",
        "\n",
        "**Linear Regression:**\n",
        "Predicting house prices based on a single feature like square footage.\n",
        "Estimating sales growth trends.\n",
        "\n",
        "**Polynomial Regression:**\n",
        "Modeling more complex phenomena like:\n",
        "Population growth.\n",
        "Temperature variations over time.\n",
        "Non-linear relationships in physics or biology.\n",
        "\n",
        "**Q25:-When is polynomial regression used?**\n",
        "\n",
        "**Ans:-**\n",
        "Polynomial Regression is used when the relationship between the independent variable(s) and the dependent variable is non-linear, and a simple linear model (i.e., Linear Regression) cannot capture the underlying patterns or trends in the data. Here are some specific situations where polynomial regression is commonly applied:\n",
        "\n",
        "**1. When Data Exhibits Non-Linear Patterns**\n",
        "Polynomial regression is ideal when the data forms a curved pattern, such as a parabola, sine curve, or any other complex shape that cannot be captured by a straight line.\n",
        "\n",
        "Example: Predicting the growth of a plant over time, where growth accelerates initially but slows down after a certain point.\n",
        "\n",
        "**2. Modeling Relationships with Multiple Turning Points**\n",
        "If the data has multiple turning points (where the curve bends in different directions), polynomial regression can model these turning points better than a linear regression model.\n",
        "\n",
        "Example: The relationship between speed and fuel efficiency, where efficiency increases at low speeds but decreases at very high speeds.\n",
        "\n",
        "**3. When Feature Interactions Are Complex**\n",
        "Polynomial regression allows the creation of interaction terms that capture more complex relationships between features and the target variable.\n",
        "\n",
        "Example: Modeling the effect of temperature and humidity on crop yield, where the interaction between both factors might be more significant than the individual effects.\n",
        "\n",
        "**4. Time Series or Trend Analysis**\n",
        "In time series data, when the data has a curved trend (like an exponential growth pattern or decaying trend), polynomial regression can fit the data more effectively than a linear regression model.\n",
        "\n",
        "Example: Predicting economic growth or stock prices where the trend isnâ€™t linear but rather follows a curve.\n",
        "\n",
        "**5. When You Want to Improve Fit for Small Data Sets**\n",
        "Polynomial regression can fit better on smaller datasets where linear regression might fail to capture the complexity of the data.\n",
        "\n",
        "Example: Small experimental datasets where a controlled, non-linear phenomenon is observed (e.g., a small set of measurements in an experiment with biological variables).\n",
        "\n",
        "**6. As a Feature Engineering Tool**\n",
        "Polynomial regression can be used as a feature engineering tool to introduce higher-degree terms into a linear model. By transforming features into polynomial terms (e.g., ğ‘¥2,ğ‘¥3), it can help capture the non-linear relationships between features in more advanced machine learning models.\n",
        "\n",
        "Example: Adding polynomial terms to a linear regression model before using it in a more complex model like a support vector machine (SVM) or decision tree.\n",
        "\n",
        "**7. When Model Simplicity and Interpretability Are Desired**\n",
        "While non-linear models like neural networks or decision trees can capture complex relationships, polynomial regression offers a simple, interpretable way to fit curves to the data without sacrificing much flexibility.\n",
        "\n",
        "Example: Predicting car maintenance costs where a simple, interpretable curve fits better than a highly complex machine learning model.\n",
        "\n",
        "**8. Fitting Data for Curve-Fitting and Smoothing**\n",
        "Polynomial regression is often used in situations where we want to smooth data or fit a model that helps visualize underlying trends. Itâ€™s a common tool in curve fitting tasks in both machine learning and traditional statistics.\n",
        "\n",
        "Example: Fitting a smooth curve to noisy data points in signal processing or environmental data analysis.\n",
        "\n",
        "**Example Use Cases for Polynomial Regression**\n",
        "\n",
        "**Physics and Engineering:**\n",
        "Modeling the trajectory of a projectile, where the relationship between time and distance follows a parabolic curve.\n",
        "\n",
        "**Biology:**\n",
        "Studying population growth, where the population growth rate accelerates and then slows down as it reaches a saturation point.\n",
        "\n",
        "**Economics and Finance:**\n",
        "Predicting demand for a product based on pricing, where the relationship isnâ€™t linear due to consumer behavior changing at different price points.\n",
        "\n",
        "**Agriculture:**\n",
        "Modeling crop yield based on multiple factors like rainfall, temperature, and soil conditions, where the relationship between these factors and yield can be non-linear.\n",
        "\n",
        "**#Conclusion**\n",
        "Polynomial regression is used when the relationship between the independent variables and the dependent variable is non-linear and more complex than a straight line can model. It is beneficial in capturing curvatures, multiple turning points, and interactions between variables. However, it should be used carefully to avoid overfitting, especially when dealing with high-degree polynomials.\n",
        "\n",
        "**Q26:-What is the general equation for polynomial regression?**\n",
        "\n",
        "**Ans:-**\n",
        "polynomial regression is a type of regression that models the relationship between the independent variable ğ‘¥ and the dependent variable ğ‘¦ as an ğ‘›-th degree polynomial. The general equation for polynomial regression is:\n",
        "\n",
        "ğ‘¦=ğ›½0+ğ›½1ğ‘¥+ğ›½2ğ‘¥2+ğ›½3ğ‘¥3+â‹¯+ğ›½ğ‘›ğ‘¥ğ‘›+ğœ–\n",
        "\n",
        "Where:\n",
        "\n",
        "->ğ‘¦ is the dependent variable (the target you are trying to predict),\n",
        "\n",
        "->ğ‘¥is the independent variable (the input feature),\n",
        "\n",
        "->ğ›½0,ğ›½1,â€¦,ğ›½ğ‘›are the coefficients of the polynomial (learned during training),\n",
        "\n",
        "->ğ‘› is the degree of the polynomial (i.e., the highest power of x),\n",
        "\n",
        "->ğœ– is the error term (the difference between the predicted and actual values).\n",
        "\n",
        "In practice, the degree ğ‘›is chosen based on the complexity of the data, and polynomial regression can be used to fit curves that linear regression cannot capture.\n",
        "\n",
        "Q**Q27:-Can polynomial regression be applied to multiple variables?**\n",
        "\n",
        "**Ans:-**Yes, polynomial regression can be extended to handle multiple variables (features), which is referred to as multivariate polynomial regression. In this case, the relationship between the dependent variable\n"
      ],
      "metadata": {
        "id": "INlfvLDMxe7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Q27:-Can polynomial regression be applied to multiple variables?\n",
        "#Ans:-\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example dataset\n",
        "X = np.array([[1500, 20], [1800, 15], [2400, 10], [3000, 8], [3500, 5]])  # Features: size and age\n",
        "y = np.array([300000, 400000, 500000, 600000, 700000])  # Target: price\n",
        "\n",
        "# Create polynomial features (degree 2)\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print coefficients and intercept\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "\n",
        "# Output predicted vs actual\n",
        "print(\"Predictions:\", y_pred)\n",
        "print(\"Actual:\", y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F-7CdaOxu5r",
        "outputId": "4720a23c-8661-4b06-c68d-24ae30882412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [-3.17049574e-10  1.70851973e+02 -3.43592953e+00 -2.20306176e-03\n",
            " -2.57212358e+00 -1.28329568e+02]\n",
            "Intercept: 177243.1825292469\n",
            "Predictions: [379265.78548283]\n",
            "Actual: [400000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q28:-What are the limitations of polynomial regression?**\n",
        "\n",
        "**Ans:-**\n",
        "Polynomial regression has several limitations that make it unsuitable for certain machine learning tasks or datasets, especially when not used carefully. Here are the main limitations:\n",
        "\n",
        "**1. Overfitting**\n",
        "\n",
        "**Problem:** High-degree polynomials can fit the training data too closely, capturing noise rather than the underlying relationship.\n",
        "\n",
        "**Consequence:** Poor generalization to new or unseen data, leading to low predictive performance.\n",
        "\n",
        "**Solution:** Use cross-validation to select an appropriate polynomial degree or apply regularization techniques like Ridge or Lasso regression.\n",
        "\n",
        "**2. Underfitting**\n",
        "\n",
        "**Problem:** If the polynomial degree is too low, the model may not capture the complexity of the data.\n",
        "\n",
        "**Consequence:** Poor fit to the training data, resulting in high bias and inaccurate predictions.\n",
        "\n",
        "**Solution:** Experiment with different polynomial degrees to balance bias and variance.\n",
        "\n",
        "**3. Extrapolation Issues**\n",
        "\n",
        "**Problem:** Polynomial regression performs poorly when predicting values outside the range of the training data.\n",
        "\n",
        "**Consequence:** Predictions in regions far from the training data can be highly inaccurate and unstable.\n",
        "\n",
        "**Solution:** Avoid using polynomial regression for extrapolation tasks or use other models like decision trees, random forests, or neural networks.\n",
        "\n",
        "**4. Sensitivity to Outliers**\n",
        "\n",
        "**Problem:** Polynomial regression is sensitive to outliers, as it tries to minimize the error for all data points.\n",
        "\n",
        "**Consequence:** A single outlier can significantly distort the curve, reducing model accuracy.\n",
        "\n",
        "**Solution:** Use robust regression methods or preprocess the data to remove outliers.\n",
        "\n",
        "**5. Interpretability**\n",
        "\n",
        "**Problem:** As the degree of the polynomial increases, the model becomes harder to interpret.\n",
        "\n",
        "**Consequence:** Understanding the relationship between variables becomes more difficult, especially with high-degree multivariate polynomials.\n",
        "\n",
        "**Solution:** Use simpler models when interpretability is important or analyze feature contributions separately.\n",
        "\n",
        "**6. Not Suitable for High-Dimensional Data**\n",
        "\n",
        "**Problem:** Polynomial regression is not efficient for datasets with a large number of features (high-dimensional data) due to the curse of dimensionality.\n",
        "\n",
        "**Consequence:** The model may overfit or become computationally infeasible.\n",
        "\n",
        "**Solution:** Use feature engineering, regularization, or other models like support vector machines, gradient boosting, or deep learning.\n",
        "\n",
        "**7. Collinearity Between Polynomial **\n",
        "\n",
        "**Problem:** Higher-degree polynomial terms (e.g., ğ‘¥2,ğ‘¥3) are often highly correlated with the original feature\n",
        "ğ‘¥, leading to multicollinearity.\n",
        "\n",
        "**Consequence:** This can make the coefficients unstable and harder to interpret.\n",
        "\n",
        "**Solution:** Apply regularization (e.g., Ridge regression) to reduce the impact of multicollinearity.\n",
        "\n",
        "**Q29:-What methods can be used to evaluate model fit when selecting the degree of a polynomial?**\n",
        "\n",
        "**Ans:-**\n",
        "When selecting the degree of a polynomial in machine learning, evaluating the model fit is crucial to ensure the model generalizes well and balances bias and variance. Here are some common methods to assess the model fit and guide the choice of polynomial degree:\n",
        "\n",
        "**1. Cross-Validation**\n",
        "\n",
        "**Description:** Split the data into training and validation sets (or use ğ‘˜-fold cross-validation) to evaluate the modelâ€™s performance on unseen data.\n",
        "\n",
        "**Process:**\n",
        "\n",
        "-Train the model on the training set using different polynomial degrees.\n",
        "\n",
        "-Evaluate performance on the validation set (e.g., using metrics like RMSE or ğ‘…2).\n",
        "\n",
        "-Select the polynomial degree that minimizes validation error.\n",
        "\n",
        "**Why it's useful:** Helps prevent overfitting by checking how the model generalizes.\n",
        "\n",
        "**2. Train-Test Split**\n",
        "Description: Split the dataset into training and testing subsets and evaluate the model on both.\n",
        "\n",
        "**Indicators of Good Fit:**\n",
        "\n",
        "->A low training error and a low testing error suggest a good fit.\n",
        "\n",
        "->A low training error and high testing error suggest overfitting.\n",
        "\n",
        "->High errors for both suggest underfitting.\n",
        "\n",
        "**Why it's useful:** Directly compares model performance on unseen data.\n",
        "\n",
        "**3. Learning Curves**\n",
        "\n",
        "**Description:** Plot the training error and validation error as a function of the polynomial degree.\n",
        "\n",
        "**What to look for:**\n",
        "\n",
        "->If the training error is high and the validation error is also high â†’ Underfitting.\n",
        "\n",
        "->If the training error is low and the validation error is high â†’ Overfitting.\n",
        "\n",
        "->The optimal degree is where both errors are minimized and closest to each other.\n",
        "Why it's useful: Provides a visual representation of bias-variance tradeoff.\n",
        "\n",
        "**Q30:-Why is visualization important in polynomial regression?**\n",
        "\n",
        "**Ans:-**\n",
        "Visualization is an essential step in polynomial regression for several reasons, particularly in machine learning, where understanding and interpreting the behavior of the model is crucial. Here's why visualization is important:\n",
        "\n",
        "**1. Understanding Model Fit**\n",
        "\n",
        "-Visualization helps assess how well the polynomial curve fits the data.\n",
        "\n",
        "=>By plotting the polynomial regression line or curve against the actual data points, you can:\n",
        "\n",
        "-Detect underfitting (a too-simple model that fails to capture the data trend).\n",
        "\n",
        "-Detect overfitting (a too-complex model that oscillates excessively to fit every point, including noise).\n",
        "\n",
        "**Example:**\n",
        "A linear model might result in a straight line missing curved patterns in the data.\n",
        "\n",
        "A high-degree polynomial might produce excessive oscillations that don't generalize well.\n",
        "\n",
        "**2. Detecting Overfitting and Underfitting**\n",
        "\n",
        "Overfitting and underfitting are common issues in polynomial regression, and visualization makes them easier to spot:\n",
        "\n",
        "Underfitting: The curve is too simple and fails to capture key trends.\n",
        "\n",
        "Overfitting: The curve closely matches training data but fluctuates unrealistically between points.\n",
        "\n",
        "Visual Clues:\n",
        "\n",
        "Underfitting: The curve misses obvious data trends (e.g., a straight line for curved data).\n",
        "\n",
        "Overfitting: The curve tightly \"hugs\" every data point but deviates wildly in other regions.\n",
        "\n",
        "**3. Inspecting Residuals**\n",
        "Residuals (differences between actual and predicted values) can be plotted to assess model performance:\n",
        "\n",
        "Randomly distributed residuals suggest a good fit.\n",
        "\n",
        "Patterns in residuals (e.g., systematic curves or clusters) suggest the model is missing key relationships.\n",
        "\n",
        "Residual Plot:\n",
        "\n",
        "Residuals vs. Predicted Values: If residuals show a pattern (e.g., parabolic), the polynomial degree may be too low.\n",
        "\n",
        "Residuals vs. Input Feature: Helps identify areas where the model performs poorly.\n",
        "\n",
        "**4. Identifying Non-Linear Relationships**\n",
        "\n",
        "Visualization helps reveal whether the data follows a non-linear trend that a polynomial regression can capture.\n",
        "\n",
        "For example, scatter plots of the data with the regression curve can confirm whether increasing the degree of the polynomial captures the true trend of the data.\n",
        "\n",
        "**5. Simplifying Model Interpretation**\n",
        "\n",
        "A visual representation of the regression curve overlaid on the data makes the model more intuitive.\n",
        "\n",
        "Non-technical stakeholders can better understand the model's predictions and why certain polynomial degrees are chosen.\n",
        "\n",
        "**6. Evaluating Extrapolation Behavior**\n",
        "\n",
        "Polynomial regression can behave unpredictably outside the range of the training data.\n",
        "\n",
        "By visualizing predictions over a wider range, you can detect unreasonable extrapolations (e.g., steep increases or decreases).\n",
        "\n",
        "Example:\n",
        "\n",
        "A quadratic polynomial might predict extreme values for inputs far from the training data, making visualization crucial for understanding these limitations.\n",
        "\n",
        "**7. Comparing Models**\n",
        "\n",
        "Visualization allows you to compare how different polynomial degrees (or models) perform on the same dataset.\n",
        "\n",
        "Overlaying curves from multiple polynomial degrees helps determine which model provides the best balance between simplicity and accuracy.\n",
        "\n",
        "**8. Debugging Model Issues**\n",
        "\n",
        "Visualization can reveal issues with the data or model, such as:\n",
        "Outliers that distort the curve.\n",
        "\n",
        "Features with inappropriate transformations.\n",
        "\n",
        "Misspecified polynomial degrees.\n",
        "\n",
        "**9. Building Trust in the Model**\n",
        "\n",
        "Visualizations make the model's behavior more transparent, helping stakeholders and users trust its predictions.\n",
        "\n",
        "Clear plots showing the alignment between predictions and data improve confidence in the model's reliability.\n",
        "\n",
        "**Q31:-How is polynomial regression implemented in Python?**\n",
        "\n",
        "**Ans:-**\n",
        "Polynomial regression is a type of regression analysis where the relationship between the independent variable x and the dependent variable y is modeled as an n-degree polynomial. It is often used in machine learning for capturing non-linear relationships.\n",
        "\n",
        "In Python, you can implement polynomial regression using libraries like NumPy, scikit-learn, and matplotlib. Here's a step-by-step guide using scikit-learn:"
      ],
      "metadata": {
        "id": "-u18gY2vyZoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Q31:-How is polynomial regression implemented in Python?\n",
        "##Ans:-\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate some non-linear data\n",
        "np.random.seed(42)\n",
        "x = np.random.rand(100, 1) * 10  # Random values between 0 and 10\n",
        "y = 3 * (x ** 2) + 2 * x + np.random.randn(100, 1) * 20  # Quadratic relationship with noise\n",
        "\n",
        "# Visualize the data\n",
        "plt.scatter(x, y, color=\"blue\", label=\"Data Points\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.title(\"Non-linear Data\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Step 1: Create polynomial features\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "x_poly = poly_features.fit_transform(x)  # Transform x to include x^2 terms\n",
        "\n",
        "# Step 2: Train a linear regression model on polynomial features\n",
        "model = LinearRegression()\n",
        "model.fit(x_poly, y)\n",
        "\n",
        "# Step 3: Predict using the trained model\n",
        "y_pred = model.predict(x_poly)\n",
        "\n",
        "# Step 4: Evaluate the model\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "\n",
        "# Step 5: Visualize the polynomial regression curve\n",
        "x_plot = np.linspace(min(x), max(x), 500).reshape(-1, 1)  # Fine-grained x for a smooth curve\n",
        "x_plot_poly = poly_features.transform(x_plot)\n",
        "y_plot = model.predict(x_plot_poly)\n",
        "\n",
        "plt.scatter(x, y, color=\"blue\", label=\"Data Points\")\n",
        "plt.plot(x_plot, y_plot, color=\"red\", label=\"Polynomial Regression Curve\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.title(\"Polynomial Regression\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "10JxZjH9yBSs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "outputId": "309763c3-50d4-45c0-bde9-de293e49cc14"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAATiVJREFUeJzt3Xl4VOX5//HPJJCwJsiShJhgAKksIrSgGKwFJBUoeGEDVhBlseJXBEtArGLdNxRbiztqW6DWoFKDVKttKSSgFYEfFMWNooZFIGH7kgh8CTA5vz9OZ8yESeZMMjPnzMz7dV25Qs6cOfPMBD03z3Pf9+MyDMMQAABAjEqwewAAAADhRLADAABiGsEOAACIaQQ7AAAgphHsAACAmEawAwAAYhrBDgAAiGkEOwAAIKYR7AAAgJhGsAPANosXL5bL5dKOHTu8xwYPHqzBgwfbNiYAsYdgB4hxnoCiWbNm2rNnzxmPDx48WOeff74NI4s9O3bskMvl8n41bdpU7du318CBA3XnnXdq165dDb723r17dd9992nLli2hGzAQJwh2gDhRVVWlRx991O5hBPSPf/xD//jHP+weRqOMHz9eL7/8sn7/+9/r7rvvVpcuXbRgwQL16NFDr776aoOuuXfvXt1///0EO0ADNLF7AAAio2/fvnrppZc0d+5cZWZm2j2cOiUlJdk9hHodO3ZMLVu2rPecH/zgB7r22mt9ju3cuVOXX365Jk2apB49eqhPnz7hHCaAGpjZAeLEnXfeKbfbbWl25/Tp03rwwQfVtWtXJScnKycnR3feeaeqqqp8zsvJydGoUaP0/vvv66KLLlKzZs3UpUsX/fGPf2zwOGvn7JSUlMjlcun111/Xww8/rKysLDVr1kxDhw7Vl19+ecbz169fr+HDhys1NVUtWrTQoEGD9K9//cvnnJ07d+rmm2/Weeedp+bNm6tdu3a66qqrfHKHpO+WANesWaObb75ZaWlpysrKatD7Ouecc7R48WKdPHlS8+fP9x4/fPiw5syZo969e6tVq1ZKSUnRiBEj9NFHH/l8BhdeeKEkacqUKd5lssWLF0uS3nvvPV111VXq1KmTkpOTlZ2drVmzZun//u//GjRWINYwswPEic6dO2vixIl66aWXdMcdd9Q7u3PDDTdoyZIlGjt2rG699VatX79e8+bN0+eff67ly5f7nPvll19q7Nix+vnPf65JkybpD3/4gyZPnqx+/fqpV69eIRv/o48+qoSEBM2ZM0cVFRWaP3++JkyYoPXr13vPWb16tUaMGKF+/frp3nvvVUJCghYtWqTLLrtM7733ni666CJJ0saNG/XBBx9o3LhxysrK0o4dO/T8889r8ODB+uyzz9SiRQuf17755pvVoUMH3XPPPTp27FiD30Nubq66du2qlStXeo99/fXXevPNN3XVVVepc+fOKi8v1wsvvKBBgwbps88+U2Zmpnr06KEHHnhA99xzj2688UZdeumlkqSBAwdKkpYtW6bjx49r2rRpateunTZs2KCnn35a33zzjZYtW9bg8QIxwwAQ0xYtWmRIMjZu3Gh89dVXRpMmTYxf/OIX3scHDRpk9OrVy/vzli1bDEnGDTfc4HOdOXPmGJKM1atXe4+dc845hiRj7dq13mP79+83kpOTjVtvvdXy2EpLS33GM2jQIO/PxcXFhiSjR48eRlVVlff4k08+aUgytm7dahiGYVRXVxvdunUzhg0bZlRXV3vPO378uNG5c2fjxz/+sc+x2tatW2dIMv74xz+eMb4f/vCHxunTpwO+n9LSUkOS8fjjj9d5zujRow1JRkVFhWEYhnHixAnD7XafcZ3k5GTjgQce8B7buHGjIclYtGjRGdf0937mzZtnuFwuY+fOnQHHDcQ6lrGAONKlSxddd911evHFF7Vv3z6/57zzzjuSpNmzZ/scv/XWWyVJf/3rX32O9+zZ0zvTIEkdOnTQeeedp6+//jqUQ9eUKVN88nk8r+l5nS1btmj79u265pprdOjQIR08eFAHDx7UsWPHNHToUK1du1bV1dWSpObNm3uvc+rUKR06dEjnnnuu2rRpo82bN5/x2lOnTlViYmJI3kerVq0kSd9++60kKTk5WQkJ5v+K3W63Dh06pFatWum8887zOxZ/ar6fY8eO6eDBgxo4cKAMw9C///3vkIwbiGYEO0Ccueuuu3T69Ok6c3d27typhIQEnXvuuT7HMzIy1KZNG+3cudPneKdOnc64xllnnaX//d//lWTewMvKyny+Tp48GfS4a7/OWWedJUne19m+fbskadKkSerQoYPP1+9+9ztVVVWpoqJCkvR///d/uueee5Sdna3k5GS1b99eHTp00JEjR7zn1NS5c+egx1uXo0ePSpJat24tSaqurtZvf/tbdevWzWcsH3/8sd+x+LNr1y5NnjxZbdu2VatWrdShQwcNGjRIkixfA4hl5OwAcaZLly669tpr9eKLL+qOO+6o8zyXy2XpenXNeBiGIUnavXv3GcFCcXFx0I0DA72OZ9bm8ccfV9++ff2e65lVueWWW7Ro0SIVFBQoNzdXqampcrlcGjdunPc6NdWcOWmsTz75RGlpaUpJSZEkPfLII7r77rt1/fXX68EHH1Tbtm2VkJCggoICv2Opze1268c//rEOHz6s22+/Xd27d1fLli21Z88eTZ482dI1gFhHsAPEobvuukt/+tOf9Nhjj53x2DnnnKPq6mpt375dPXr08B4vLy/XkSNHdM455wT1WhkZGT4JuZLCUnbdtWtXSVJKSory8vLqPffPf/6zJk2apN/85jfeYydOnNCRI0dCPq6a1q1bp6+++sqnLP3Pf/6zhgwZot///vc+5x45ckTt27f3/lxX8Ll161b95z//0ZIlSzRx4kTv8dqfORDPWMYC4lDXrl117bXX6oUXXlBZWZnPYz/5yU8kSQsWLPA5/sQTT0iSRo4cGdRrNWvWTHl5eT5fniWoUOrXr5+6du2qX//6196lopoOHDjg/XNiYqJ3Rsjj6aefltvtDvm4PHbu3KnJkycrKSlJt912W71jWbZs2Rndrj29fWoHZJ4Zr5rXMAxDTz75ZCiHD0Q1ZnaAOPWrX/1KL7/8srZt2+ZTIt6nTx9NmjRJL774oo4cOaJBgwZpw4YNWrJkia688koNGTLExlHXLSEhQb/73e80YsQI9erVS1OmTNHZZ5+tPXv2qLi4WCkpKXrrrbckSaNGjdLLL7+s1NRU9ezZU+vWrdM///lPtWvXLiRj2bx5s/70pz+purpaR44c0caNG/XGG2/I5XLp5Zdf1gUXXOA9d9SoUXrggQc0ZcoUDRw4UFu3btUrr7yiLl26+Fyza9euatOmjRYuXKjWrVurZcuWGjBggLp3766uXbtqzpw52rNnj1JSUvTGG294c5kAEOwAcevcc8/VtddeqyVLlpzx2O9+9zt16dJFixcv1vLly5WRkaG5c+fq3nvvtWGk1g0ePFjr1q3Tgw8+qGeeeUZHjx5VRkaGBgwYoP/5n//xnvfkk08qMTFRr7zyik6cOKFLLrlE//znPzVs2LCQjGPp0qVaunSpmjRpopSUFHXr1k0FBQW66aabzki0vvPOO3Xs2DEVFhbqtdde0w9+8AP99a9/PSOfqmnTplqyZInmzp2rm266SadPn9aiRYs0efJkvfXWW/rFL36hefPmqVmzZvrpT3+qGTNm0KUZ+C+XUXv+FAAAIIaQswMAAGIawQ4AAIhpBDsAACCmEewAAICYRrADAABiGsEOAACIafTZkbmnzt69e9W6dWvL+wEBAAB7GYahb7/9VpmZmUpIqHv+hmBH0t69e5WdnW33MAAAQAPs3r1bWVlZdT5OsCOpdevWkswPy7MTMQAAcLbKykplZ2d77+N1IdjRd7sJp6SkEOwAABBlAqWgkKAMAABiGsEOAACIaQQ7AAAgppGzY1F1dbVOnjxp9zAQYU2bNlViYqLdwwAANALBjgUnT55UaWmpqqur7R4KbNCmTRtlZGTQgwkAohTBTgCGYWjfvn1KTExUdnZ2vU2LEFsMw9Dx48e1f/9+SVLHjh1tHhEAoCEIdgI4ffq0jh8/rszMTLVo0cLu4SDCmjdvLknav3+/0tLSWNICgCjENEUAbrdbkpSUlGTzSGAXT5B76tQpm0cCAGgIgh2LyNeIX/zuASC6sYwFAADCwu2W3ntP2rdP6thRuvRSyY5sAGZ2EFXuu+8+9e3b1+5hAAACKCqScnKkIUOka64xv+fkmMcjjWAnRk2ePFkul0sul0tNmzZVenq6fvzjH+sPf/hD0CX0ixcvVps2bUIyrsGDB3vH1axZM/Xs2VPPPfec5efPmTNHq1atCuo1c3JytGDBgiBHCgBoqKIiaexY6ZtvfI/v2WMej3TAQ7ATIW63VFIiLV1qfv9v3nNYDR8+XPv27dOOHTv07rvvasiQIZo5c6ZGjRql06dPh38AdZg6dar27dunzz77TD/72c80ffp0LV261NJzW7VqpXbt2oV5hACAhnK7pZkzJcM48zHPsYKCyNwHPQh2IsCuqbzk5GRlZGTo7LPP1g9+8APdeeedWrFihd59910tXrzYe94TTzyh3r17q2XLlsrOztbNN9+so0ePSpJKSko0ZcoUVVRUeGdk7rvvPknSyy+/rP79+6t169bKyMjQNddc4+1JU58WLVooIyNDXbp00X333adu3brpL3/5iyRp165dGj16tFq1aqWUlBT97Gc/U3l5ufe5tZexJk+erCuvvFK//vWv1bFjR7Vr107Tp0/3Vk4NHjxYO3fu1KxZs7zjl6SdO3fqiiuu0FlnnaWWLVuqV69eeueddxrzcQMAZObo1J7RqckwpN27zfMihWAnzJw2lXfZZZepT58+KqrxwgkJCXrqqaf06aefasmSJVq9erV++ctfSpIGDhyoBQsWKCUlRfv27dO+ffs0Z84cSWYp9oMPPqiPPvpIb775pnbs2KHJkycHPabmzZvr5MmTqq6u1ujRo3X48GGtWbNGK1eu1Ndff62rr7663ucXFxfrq6++UnFxsZYsWaLFixd7g7mioiJlZWXpgQce8I5fkqZPn66qqiqtXbtWW7du1WOPPaZWrVoFPXYAgK///m82ZOeFAtVYYRRoKs/lMqfyRo+ObHZ69+7d9fHHH3t/Ligo8P45JydHDz30kG666SY999xzSkpKUmpqqlwulzIyMnyuc/3113v/3KVLFz311FO68MILdfToUUuBg9vt1tKlS/Xxxx/rxhtv1KpVq7R161aVlpYqOztbkvTHP/5RvXr10saNG3XhhRf6vc5ZZ52lZ555RomJierevbtGjhypVatWaerUqWrbtq0SExO9s08eu3bt0pgxY9S7d2/v+AEAjWe12Xwkm9IzsxNGTpzKM1/X8Okd889//lNDhw7V2WefrdatW+u6667ToUOHdPz48Xqvs2nTJl1xxRXq1KmTWrdurUGDBkkyA4n6PPfcc2rVqpWaN2+uqVOnatasWZo2bZo+//xzZWdnewMdSerZs6fatGmjzz//vM7r9erVy6ezcceOHQMup/3iF7/QQw89pEsuuUT33nuvT/AHAGi4Sy+VsrLMf9D743JJ2dnmeZFCsBNGTpzKk6TPP/9cnTt3liTt2LFDo0aN0gUXXKA33nhDmzZt0rPPPitJ9e7yfuzYMQ0bNkwpKSl65ZVXtHHjRi1fvjzg8yRpwoQJ2rJli0pLS3Xs2DE98cQTjdpzrGnTpj4/u1yugBVnN9xwg77++mtdd9112rp1q/r376+nn366wWMAAJgSE6UnnzT/XDvg8fy8YEFkVzQIdsLIiVN5q1ev1tatWzVmzBhJ5uxMdXW1fvOb3+jiiy/W9773Pe3du9fnOUlJSd5tMzy++OILHTp0SI8++qguvfRSde/e3VJysiSlpqbq3HPP1dlnn+0T5PTo0UO7d+/W7t27vcc+++wzHTlyRD179mzoW/Y7fknKzs7WTTfdpKKiIt1666166aWXGvwaAIDv5OdLf/6zdPbZvsezsszj+fmRHQ/BThjZPZVXVVWlsrIy7dmzR5s3b9Yjjzyi0aNHa9SoUZo4caIk6dxzz9WpU6f09NNP6+uvv9bLL7+shQsX+lwnJydHR48e1apVq3Tw4EEdP35cnTp1UlJSkvd5f/nLX/Tggw82arx5eXnq3bu3JkyYoM2bN2vDhg2aOHGiBg0apP79+zf4ujk5OVq7dq327NmjgwcPSjLzlP7+97+rtLRUmzdvVnFxsXr06NGo8QMAvpOfL+3YIRUXS4WF5vfS0sgHOhLBTljZPZX3t7/9TR07dlROTo6GDx+u4uJiPfXUU1qxYoU3x6VPnz564okn9Nhjj+n888/XK6+8onnz5vlcZ+DAgbrpppt09dVXq0OHDpo/f746dOigxYsXa9myZerZs6ceffRR/frXv27UeF0ul1asWKGzzjpLP/rRj5SXl6cuXbrotddea9R1H3jgAe3YsUNdu3ZVhw4dJJnJ0dOnT1ePHj00fPhwfe973wuquSEAILDERGnwYGn8ePO7HVtFSJLLMPzVCsWXyspKpaamqqKiQikpKT6PnThxQqWlpercubOaNWvWoOsXFZlVWTWTlbOzzUDHjggXwQnF3wEAQOjVd/+uidLzCMjPN8vLnbAZGgAA8YZgJ0I8U3kAACCyyNkBAAAxjWAHAADENIIdi8jjjl/87gEgupGzE4CnRPvkyZNq3ry5zaOBHTzbZtTu1AwA8c7tjo7iG4KdAJo0aaIWLVrowIEDatq0aaO2NUB0MQxDx48f1/79+9WmTRuf/bcAIN75a6uSlWX2l3NaWxX67Chwnf7JkydVWloacL8lxKY2bdooIyPDZ/NUAIhnRUXS2LHmhtY1ef43GaktIaz22SHYkbUPq7q6OuAGl4g9TZs2ZUYHAGpwu6WcHN8ZnZpcLnOGp7Q0/EtaNBUMsYSEBLrnAgDi3nvv1R3oSOZsz+7d5nlO6S9HAgoAALBs377QnhcJBDsAAMCyjh1De14kEOwAAADLLr3UzMmpq2bD5TI3u7700siOqz4EOwAAwLLERLO8XDoz4PH8vGCBs/rt2BrsPP/887rggguUkpKilJQU5ebm6t133/U+fuLECU2fPl3t2rVTq1atNGbMGJWXl/tcY9euXRo5cqRatGihtLQ03XbbbTp9+nSk3woAAHEjP98sLz/7bN/jWVmRKzsPhq3VWFlZWXr00UfVrVs3GYahJUuWaPTo0fr3v/+tXr16adasWfrrX/+qZcuWKTU1VTNmzFB+fr7+9a9/SZLcbrdGjhypjIwMffDBB9q3b58mTpyopk2b6pFHHrHzrQEAENPy86XRo6Ojg7Lj+uy0bdtWjz/+uMaOHasOHTqosLBQY8eOlSR98cUX6tGjh9atW6eLL75Y7777rkaNGqW9e/cqPT1dkrRw4ULdfvvtOnDggJKSkiy9ptU6fQAA4BxW79+Oydlxu9169dVXdezYMeXm5mrTpk06deqU8vLyvOd0795dnTp10rp16yRJ69atU+/evb2BjiQNGzZMlZWV+vTTT+t8raqqKlVWVvp8AQCA2GR7sLN161a1atVKycnJuummm7R8+XL17NlTZWVlSkpKUps2bXzOT09PV1lZmSSprKzMJ9DxPO55rC7z5s1Tamqq9ys7Ozu0bwoAADiG7cHOeeedpy1btmj9+vWaNm2aJk2apM8++yysrzl37lxVVFR4v3bv3h3W1wMAAPaxfbuIpKQknXvuuZKkfv36aePGjXryySd19dVX6+TJkzpy5IjP7E55ebkyMjIkSRkZGdqwYYPP9TzVWp5z/ElOTlZycnKI3wkAAHAi22d2aquurlZVVZX69eunpk2batWqVd7Htm3bpl27dik3N1eSlJubq61bt2r//v3ec1auXKmUlBT17Nkz4mMHAADOY+vMzty5czVixAh16tRJ3377rQoLC1VSUqK///3vSk1N1c9//nPNnj1bbdu2VUpKim655Rbl5ubq4osvliRdfvnl6tmzp6677jrNnz9fZWVluuuuuzR9+nRmbgAAgCSbg539+/dr4sSJ2rdvn1JTU3XBBRfo73//u3784x9Lkn77298qISFBY8aMUVVVlYYNG6bnnnvO+/zExES9/fbbmjZtmnJzc9WyZUtNmjRJDzzwgF1vCQAAOIzj+uzYgT47AABEH6v3b9sTlAEAgPO43dHRHdkKgh0AAOCjqEiaOVP65pvvjmVlmRuAOm3fKysIdgAAiHM1Z3G2b5fuvffMc/bskcaOdeZGn4EQ7AAAEMf8zeL4YxiSyyUVFJgbgEbTkpbj+uwAAIDIKCoyZ2sCBToehiHt3m3OAkUTgh0AAOKQ223O6DSkJnvfvtCPJ5xYxgIAIEYEU0H13nvWZ3RqS0sL/vXsRLADAEAMCLaCqrGzM9FUscUyFgAAUa6u3BtPBVVR0ZnP6dix4a/39tvBv56d6KAsOigDACIvVEtAbreUk1P3kpTLZc64lJb6Xt/zvD17gs/b6dBBOnAguNcLB6v3b2Z2AACIsKIiM9AYMkS65hrze05Ow2ZEAuXe1FVBlZhoLjlJZoBihctVf6BT3+vZiWAHAIAIasiSU32s5t74Oy8/32wSePbZgZ/vCYgmTAjtuCKBYAcAgAipr9zbc6ygwDzPKqu5N+Xl0tKlUkmJ7/Xz86UdO6TiYqmw0Pz++uvmUlRNWVlmYDR6dGjHFQnk7IicHQBAZJSUmEtWgRQXS4MHW7umldybxETfAMdK1VRdOUWBXo+cHQAA4lhDl5zcbjNQ8jczYyX3pvZMkZUls8REM+AaP9787glc6ns9z88LFjir3w7BDgAAEWJ1aafmeVaSmevKvakr4Gjoklmg1/MsdTmtzw7LWGIZCwAQGcEuAXmSmWuf65lBqR1Y1Fx6Ki+XZs0KPKZglsz8vR87OyhbvX/TQRkAgAjxLAGNHWsGLDWDmNpLQIGSmf3tQO5ZepLMJS8rGlM1VfP1nIxlLAAAIsjqElBD++d4NGTJLFYxswMAQITl55szMvUtATWmf45kXi8rK/CS2aWXBj/+aEOwAwCADQItATV2ZiaYJbNYxzIWAAAO5JmZqauc3OWSsrPrn5mJtqqpcGFmBwAABwrVzIyVJbNYR7ADAIBDeWZmZs70TVbOyjIDHaszM9FSNRUuBDsAADgYMzONR7ADAIDDxfvMTGMR7AAAgKDY3Tk5WAQ7AADAsqIi/zlEgXZRtxOl5wAAwBLPXl21Oztb2UXdTgQ7AAAgoEB7dUkN30U93Ah2AABAQI3dq8tOBDsAACCgxu7VZSeCHQAAEFA076JOsAMAAAIKxV5ddiHYAQAAAXn26pLODHicvos6wQ4AALAkWndRp6kgAACwLBr36rJ1ZmfevHm68MIL1bp1a6WlpenKK6/Utm3bfM4ZPHiwXC6Xz9dNN93kc86uXbs0cuRItWjRQmlpabrtttt0+vTpSL4VAADihmevrvHjze9ODnQkm2d21qxZo+nTp+vCCy/U6dOndeedd+ryyy/XZ599ppYtW3rPmzp1qh544AHvzy1atPD+2e12a+TIkcrIyNAHH3ygffv2aeLEiWratKkeeeSRiL4fAAAiIdr2prKbyzD89UK0x4EDB5SWlqY1a9boRz/6kSRzZqdv375asGCB3+e8++67GjVqlPbu3av09HRJ0sKFC3X77bfrwIEDSkpKCvi6lZWVSk1NVUVFhVJSUkL2fgAACLVo3JsqXKzevx2VoFxRUSFJatu2rc/xV155Re3bt9f555+vuXPn6vjx497H1q1bp969e3sDHUkaNmyYKisr9emnn/p9naqqKlVWVvp8AQDgdNG6N5XdHJOgXF1drYKCAl1yySU6//zzvcevueYanXPOOcrMzNTHH3+s22+/Xdu2bVPRf3+jZWVlPoGOJO/PZWVlfl9r3rx5uv/++8P0TgAACL1Ae1O5XObeVKNHs6RVm2OCnenTp+uTTz7R+++/73P8xhtv9P65d+/e6tixo4YOHaqvvvpKXbt2bdBrzZ07V7Nnz/b+XFlZqezs7IYNHACACAhmb6rBgyM2rKjgiGWsGTNm6O2331ZxcbGysrLqPXfAgAGSpC+//FKSlJGRofLycp9zPD9nZGT4vUZycrJSUlJ8vgAAcLJo3pvKbrYGO4ZhaMaMGVq+fLlWr16tzp07B3zOli1bJEkd/7v5Rm5urrZu3ar9+/d7z1m5cqVSUlLUs2fPsIwbAIBIi+a9qexmazXWzTffrMLCQq1YsULnnXee93hqaqqaN2+ur776SoWFhfrJT36idu3a6eOPP9asWbOUlZWlNWvWSDJLz/v27avMzEzNnz9fZWVluu6663TDDTdYLj2nGgsA4HRut5STYyYj+7tzu1xmVVZpafzk7Fi9f9sa7Ljq2E1s0aJFmjx5snbv3q1rr71Wn3zyiY4dO6bs7Gz99Kc/1V133eXzpnbu3Klp06appKRELVu21KRJk/Too4+qSRNrKUkEOwCAaOCpxpJ8Ax7P7dTJWzaEQ1QEO05BsAMACJZdjf389dnJzjY34YynQEeyfv92TDUWAADRws7GftG4N5XdmNkRMzsAAOs8S0m1757xupRkp6jsoAwAgJMFauwnmY393O6IDgsBEOwAAGBRMI394BwEOwAAWERjv+hEgjIAABaFo7GfXVVd8YSZHQAALLr0UrPqqo42cXK5zDLwSy+1dr2iIrNR4JAh0jXXmN9zcti9PNQIdgAAsCgx0Swvl84MeDw/L1hgbWbGU9VVOwdozx7zOAFP6BDsAAAQhPx8s7z87LN9j2dlWS87p6orssjZAQAgSI1t7BdMVdfgwSEZclwj2AEAoAESExseiFDVFVksYwEAEGHhqOpC3Qh2AACIsFBXdaF+BDsAAERYKKu6EBjBDgAANghFVResIUEZAIB6hLPDcWOrumANwQ4AAHUoKjL74dQsE8/KMpegQjXz0piqLljDMhYAAH7Q4Th2EOwAAFALHY5jC8EOAAC1BNPhGM5HsAMAQC10OI4tBDsAANRCh+PYQrADAEAtdDiOLQQ7AADUEkyHY7dbKimRli41v5O07DwEOwAA6MygZfTowB2Oi4qknBxpyBDpmmvM7zk5lKU7DU0FAQBxz1/zwA4dpAkTpMWLzZ/37/ftcOzpw1O7PN3Th4ctH5zDZRj+ugjEl8rKSqWmpqqiokIpKSl2DwcAEEF1BS011e6a7HabMzh1lae7XOZzSkvZ+iGcrN6/WcYCAMSt+poH1vTNN75dk+nDE10IdgAAcStQ0FKbp2syfXiiC8EOACBuBROM1JytoQ9PdCHYAQDErYYEI/v20Ycn2hDsAADCzqm9aAIFLf507BhcHx7Yj2AHABBWTu5FU1/QUlvt2Zr8/MB9eOAMlJ6L0nMACJe6yro9gYVTggJ/fXZqqm+8breZx7Nvn28fHoSf1fs3wY4IdgAgHKKtF40naFmxQvrTn6SDB797LDvbXJZyQmCG7xDsBIFgBwBCr6TEXLIKpLhYGjw43KMJDrM10cHq/ZvtIgAAYRHNvWgSE50XgKHhbE1Qnjdvni688EK1bt1aaWlpuvLKK7Vt2zafc06cOKHp06erXbt2atWqlcaMGaPy8nKfc3bt2qWRI0eqRYsWSktL02233abTp09H8q0AAGqhFw2cwtZgZ82aNZo+fbo+/PBDrVy5UqdOndLll1+uY8eOec+ZNWuW3nrrLS1btkxr1qzR3r17lV9j0dTtdmvkyJE6efKkPvjgAy1ZskSLFy/WPffcY8dbAgD8VzC9aJxamo7Y4KicnQMHDigtLU1r1qzRj370I1VUVKhDhw4qLCzU2LFjJUlffPGFevTooXXr1uniiy/Wu+++q1GjRmnv3r1KT0+XJC1cuFC33367Dhw4oKSkpICvS84OAISHpxpL8q3IqlndJJ1ZCVV7403An6jcCLSiokKS1LZtW0nSpk2bdOrUKeXl5XnP6d69uzp16qR169ZJktatW6fevXt7Ax1JGjZsmCorK/Xpp5/6fZ2qqipVVlb6fAEAQi9QLxrJDIZqV2zt2eO78SbQGI5JUK6urlZBQYEuueQSnX/++ZKksrIyJSUlqU2bNj7npqenq6yszHtOzUDH87jnMX/mzZun+++/P8TvAADgT36+NHr0mdVNklma7m99wTDM2Z+CAvO5VEKhMRwT7EyfPl2ffPKJ3n///bC/1ty5czV79mzvz5WVlcrOzg776wJAvPJX3VRSUv+O4zU33qQyCo3hiGBnxowZevvtt7V27VplZWV5j2dkZOjkyZM6cuSIz+xOeXm5MjIyvOds2LDB53qeai3PObUlJycrOTk5xO8CABCMSJem0zsnftmas2MYhmbMmKHly5dr9erV6ty5s8/j/fr1U9OmTbVq1SrvsW3btmnXrl3Kzc2VJOXm5mrr1q3av3+/95yVK1cqJSVFPXv2jMwbAQAELZKl6U7enwvhZ2s11s0336zCwkKtWLFC5513nvd4amqqmjdvLkmaNm2a3nnnHS1evFgpKSm65ZZbJEkffPCBJLP0vG/fvsrMzNT8+fNVVlam6667TjfccIMeeeQRS+OgGgsAIs+zncSePf7zdkK1nUS07M+F4EXFdhGuOpovLFq0SJMnT5ZkNhW89dZbtXTpUlVVVWnYsGF67rnnfJaodu7cqWnTpqmkpEQtW7bUpEmT9Oijj6pJE2urdAQ7AGAPK6XpjQlEom1/LgQnKoIdpyDYAQD7+NtxPFQbb0bz/lwIjL2xAABRoa7S9FDMtETz/lwIHYIdAIDtwrXxJvtzQXJYB2UAAEIpmP25ELsIdgAAUau+DUQ9fXX8VWJJ3wVACxaQnBzrWMYCAEQlf4nNng1EpTMfS0z0DYayskKTBA3nI9gBAESdunrn7NkjjRnj/znV1eZ3z35bdFCOH5Sei9JzALBbMFs5BOqdUx/66sQWq/dvcnYAALYKdiuH995rWKAj+W4uivhBsAMAsI1nOap28LJnj3ncX8ATip449NWJLwQ7AABbuN1mErG/ZArPsYIC36RiKTQ9ceirE18IdgAAtgi0HFXXklOg3jmB0Fcn/hDsAABs0dCtHBITvysvb0jAQ1+d+EOwAwCwhdWlpO3bzzyWn2/uiH722cG9ZkEBfXXiEcEOAMAWnuWoQF566cy8HckMWnbsMHcsv+sua685enRQQ0SMINgBANgiMVGaOjXwed98U3epuGcD0bvvDrw0lZgoDRwY9DARAwh2AAC26dbN2nmB8ns++MD/7E9Nbrd5HuIPwQ4AwDZW83YCndfQZGfEB4IdAIBtApWRu1zWSsVDFTQhNhHsAADCwu2WSkqkpUvN7/6WmeorI/f8bKVU3EqyM/114hfBDgAg5ILZ76quMvKsLPO4lVLxxERp/Pj6zxk3jv468Ypdz8Wu5wAQSp79rmrfXTwzNXUFMMHsfO7vuYF2Qs/OZrfzWGP1/k2wI4IdAAiVQEGHy2XO2IQ66CgpMWePAikuNkvVERus3r9ZxgIAhExD97tqLKqxUB+CHQBAyNgVdFCNhfoQ7AAAQsauoCNUJeyITQQ7AICQsSvoCFUJO2ITwQ4ARAErPWucwM6gIxQl7IhNVGOJaiwAzlZUJM2c6Zv4m5VlBhVOvYH7G3N2thnohHvMjSlhR3Sh9DwIBDsAnKqhPWucgKAD4UawEwSCHQBOZFfPGiBa0GcHAKKcXT1rgFhDsAMADkWjPCA0mtg9AACAf7HQKI+8HTgBMzsA4FDR3igvmJ3PgXCyHOzs3bs3nOMAANQSzY3yPFVktXOO9uwxjxPwIJIsBzu9evVSYWFhOMcCAKglGhvlud1mjx1/tb6eYwUFzm2MiNhjOdh5+OGH9T//8z+66qqrdPjw4XCOCQBQQ36+tGOHVFwsFRaa30tL7Qt0AnVzpooMTmM52Ln55pv18ccf69ChQ+rZs6feeuutRr/42rVrdcUVVygzM1Mul0tvvvmmz+OTJ0+Wy+Xy+Ro+fLjPOYcPH9aECROUkpKiNm3a6Oc//7mOHj3a6LEBgJMkJkqDB0vjx5vf7Vq6spKHQxUZnCaoaqzOnTtr9erVeuaZZ5Sfn68ePXqoSRPfS2zevNny9Y4dO6Y+ffro+uuvV34d/0QZPny4Fi1a5P05OTnZ5/EJEyZo3759WrlypU6dOqUpU6boxhtvZMkNAEKsrm7Onjwcz7JaLFSRIbYEXXq+c+dOFRUV6ayzztLo0aPPCHaCMWLECI0YMaLec5KTk5WRkeH3sc8//1x/+9vftHHjRvXv31+S9PTTT+snP/mJfv3rXyszM7PBYwMAfCdQHo7LZebhjB79XRXZnj3+z/d0fnZqFRliT1CRyksvvaRbb71VeXl5+vTTT9WhQ4dwjcurpKREaWlpOuuss3TZZZfpoYceUrt27SRJ69atU5s2bbyBjiTl5eUpISFB69ev109/+lO/16yqqlJVVZX358rKyvC+CQCIcsHk4QwebFaRjR1rBjY1Ax6nV5EhNlnO2Rk+fLhuv/12PfPMMyoqKopIoDN8+HD98Y9/1KpVq/TYY49pzZo1GjFihNz/zYYrKytTWlqaz3OaNGmitm3bqqysrM7rzps3T6mpqd6v7OzssL4PAIh2webhRGMVGWKX5Zkdt9utjz/+WFlZWeEcj49x48Z5/9y7d29dcMEF6tq1q0pKSjR06NAGX3fu3LmaPXu29+fKykoCHgCoR0PycPLzzWUtOijDbpaDnZUrV4ZzHJZ06dJF7du315dffqmhQ4cqIyND+/fv9znn9OnTOnz4cJ15PpKZB1Q70RkAULeG5uF4qsgAO0XVdhHffPONDh06pI7//adDbm6ujhw5ok2bNnnPWb16taqrqzVgwAC7hgkAMSeauzkDtgY7R48e1ZYtW7RlyxZJUmlpqbZs2aJdu3bp6NGjuu222/Thhx9qx44dWrVqlUaPHq1zzz1Xw4YNkyT16NFDw4cP19SpU7Vhwwb961//0owZMzRu3DgqsQAgxMjDQbRyGYa/CcnIKCkp0ZAhQ844PmnSJD3//PO68sor9e9//1tHjhxRZmamLr/8cj344INKT0/3nnv48GHNmDFDb731lhISEjRmzBg99dRTatWqleVxVFZWKjU1VRUVFUpJSQnJewOAWMVO5nAKq/dvW4MdpyDYARDNCD4Qr6zevxveERAAYLuiIrPZX80eOFlZZn4Ny0qAKaoSlAEA3/Fs31C72Z9n+4aa+1UB8YxgBwCiUKDtGyRz+4baO5ID8YhgBwCiUDDbNwDxjmAHAKJQsNs3APGMYAcAolBDtm8A4hXBDgBEIc/2DbW7GXu4XFJ29pnbNwDxiGAHAKKI2y2VlEivvy5NnWoeY/sGoH702QGAKOGvp067dub3Q4e+O5aVZQY69NkBTAQ7ABAFPD11apeaHz5sHrv/fqlbNzooA/4Q7ACAwwXqqeNySb/7nVRa2rggh20nEKvI2QEAh4tET52iIiknRxoyRLrmGvN7Tg5dmBEbCHYAIAieBOGlS83vkehQHO6eOmw7gVhHsAMAFtk1+xHOnjpsO4F4QLADABbYOfsRzp46bDuBeECwAwAB2D37kZgoPfmk+edQ99Rh2wnEA4IdAAjACbMf+fnSn/8snX227/GsLPN4Q3vqsO0E4gGl5wAQgFNmP/LzpdGjQ1se7lki27PH/8yVy2U+zrYTiGYEOwAQgJNmPxITpcGDrZ8fqHeOZ4ls7FgzsKkZ8LDtBGIFy1gAEEC0brpptXosXEtkgFO4DMPfxGV8qaysVGpqqioqKpSSkmL3cAA4kKcaS/I/++G0oKCu7SXqGy8dlBFtrN6/CXZEsAPAGn8bcWZnO2/TTbfbnMGpK6nak4fT2O0lALtZvX+TswMAFoUjQbimUM2sBFM9Fkz+DxCtCHYAIAjBJghb5W/WKCvLTB4OdtbIKdVjgFOQoAwADRDKPbJC3Z3ZSdVjgBMQ7ABAkEK5R1Y4ujNHa/UYEC4EOwAQhFDPwoSjO3M4t5cAohHBDgBYFI5ZmHDl19A7B/gOCcoAYFE4qpzCmV8T7uoxIFoQ7ACAReGYhQn33lThqh4DognLWABgUThmYcivAcKPYAcALApXlRP5NUB4EewAgEXhnIXJz5d27JCKi6XCQvP7l19KbduGppcPEM8IdgAgCOGchfHk14wfLx0+LHXtGppePkC8YyNQsREogOCFc4fwhuxYDsQjdj0PAsEOAKdgx3LAOqv3b5axAMBBwtFRGYh3tgY7a9eu1RVXXKHMzEy5XC69+eabPo8bhqF77rlHHTt2VPPmzZWXl6ft27f7nHP48GFNmDBBKSkpatOmjX7+85/r6NGjEXwXABA67FgOhJ6twc6xY8fUp08fPfvss34fnz9/vp566iktXLhQ69evV8uWLTVs2DCdOHHCe86ECRP06aefauXKlXr77be1du1a3XjjjZF6CwAQUuxYDoSeY3J2XC6Xli9friuvvFKSOauTmZmpW2+9VXPmzJEkVVRUKD09XYsXL9a4ceP0+eefq2fPntq4caP69+8vSfrb3/6mn/zkJ/rmm2+UmZlp6bXJ2QHgFJ6cnUAdlcnZAWIgZ6e0tFRlZWXKy8vzHktNTdWAAQO0bt06SdK6devUpk0bb6AjSXl5eUpISND69evrvHZVVZUqKyt9vgDACeioDISeY4OdsrIySVJ6errP8fT0dO9jZWVlSktL83m8SZMmatu2rfccf+bNm6fU1FTvV3Z2dohHDwANR0dlILQcG+yE09y5c1VRUeH92r17t91DAgAf/joql5YS6AAN4dhdzzMyMiRJ5eXl6lgjE6+8vFx9+/b1nrN//36f550+fVqHDx/2Pt+f5ORkJScnh37QABBC7FgOhIZjZ3Y6d+6sjIwMrVq1ynussrJS69evV25uriQpNzdXR44c0aZNm7znrF69WtXV1RowYEDExwwAAJzH1pmdo0eP6ssvv/T+XFpaqi1btqht27bq1KmTCgoK9NBDD6lbt27q3Lmz7r77bmVmZnortnr06KHhw4dr6tSpWrhwoU6dOqUZM2Zo3LhxliuxAMAjVFtAhHMrCQANYNiouLjYkHTG16RJkwzDMIzq6mrj7rvvNtLT043k5GRj6NChxrZt23yucejQIWP8+PFGq1atjJSUFGPKlCnGt99+G9Q4KioqDElGRUVFqN4agCjzxhuGkZVlGGbBt/mVlWUet+M6AAKzev92TJ8dO9FnB4hvodp4M1TXYWYIsIaNQINAsAPEr1BtvBmq6xQVSTNn+l4nK8vsvUMlFuAr6psKAkAkhGrjzVBcxzMzVPs6e/aYx4uK6h8DAP8IdgDEtVBtvNnY67jd5oyOv7l2z7GCAvM8AMEh2AEQVdxuqaREWrrU/N7Ym7/VDTW3bw/Ndeo6L1QzTADORLADIGoUFZl5MUOGSNdcY37PyWnc8s6ll5o5MYG89FL9gZXnOrX3s/JwuaTsbPM8f0I1wwTgTAQ7AKJCuPJZEhOlqVMDn/fNN/XPqjR2A8/GzgwBqBvBDgDHC3c+S7du1s4LNKvSmA08GzszBKBuBDsAHC/c+SyhnFVp6Aae9c0MedQ3MwSgbo7dCBQAPMKdz+KZVdmzx//skadHjtVZlYZu4OmZGbrxRunQId/H2rYN/noATMzsAHC8cOezNDbfJtRqBzqSdPgwvXaAhiLYAeB4kchnaUy+Tah4cpP8odcO0HAEOwAcL1IzLw3NtwkVeu0A4UHODoCo4Jl58bdv1IIFoQtIGppvEwr02gHCg2AHQNTIz5dGjw7djuBO212cXjtAeBDsAIi4xgQZoZp5ceLu4qGuCgNgImcHQESFY8uHhozBibuLO60qDIgVLsPw9++H+FJZWanU1FRVVFQoJSXF7uEAMaP2DM6BA9LVV585a+G5kUei6sntNoOruhKBPbMnpaX2BRX+Zp2ys0ObmwTEAqv3b4IdEezA2ZyWV2KVvxt2YmLdZdORCjJKSszZpECKi+1LVJai9/cORJLV+zc5O4CDOTGvxArPMlHtf0rV1x+mZll1OIOMaKl4srMqDIg15OwADuXUvJJA6tu004pwBxlUPAHxh2AHcKBw7/IdToEa4wUSqiDD7TaXrJYuNb97Pit2FwfiD8EO4EDR3Em3oTMzoQwy6qv4ouIJiD8EO4ADRUteiT8NmZkJZZBhZfnPCftgAYgcqrFENRacoWb1TXm5NGtW4OfYXTHkj6e0u67GeNKZVVmhKqsOtqy85meelmaes38/1U9AtKAaC4giDS3TdmJeiWeZaOxYc5w1Ax7PDM6rr0rt24e+rDqY5b/Bg7+reCoqkiZPjr6qNwDWEOwANgu2TDsa8koitWlnbQ1Z/qvr8/cse7GsBUQ/lrHEMhbsE2jZRQrfkk8kRLoxXrANA6OhmzKAurGMBUQBK2Xabrf0299K6enRl0sS6cZ4nrLy+j7TmhVfwS57AYhOVGPB8erqlxILrC67pKdL48d/l2cC/xITzc+pPuPGffcZRnPVGwDrCHbgaE7YITuc4qWbb6QCVrfbfI36vPrqd68fL58/EO8IduBY0bpdQjDioZtvJANWK8uCNZsxxsPnD4BgBw4VzdslBCPWu/lGOmANdlkq1j9/ACaCHTgyJyaat0sIVqBuvqNHO+/3Y4UdAWtDlqXopgzEPqqx4py/ZnZOaKYWb4mj+flmUFO7THvFijNLo53w+7HCjkonz7JUXd2b62rGWNfnz4wOEBsIduKYk5upxWPiaO0y7VD8fgL1uQlnHxw7AlYr3ZvrWpaKdJk8gMhhGStOOT0nJt4TR0Px+wmUGBzuxGG7AlaWpQDU5uhg57777pPL5fL56t69u/fxEydOaPr06WrXrp1atWqlMWPGqLy83MYRRw+n58TEe+JoY38/gRKDf/nL8CcO2xmw5udLO3aYnZILC83vpaUEOkC8cnSwI0m9evXSvn37vF/vv/++97FZs2bprbfe0rJly7RmzRrt3btX+fzfzJJoyImJ53+hN+b3Y2VW6Iknwj+rZ3fA6lmWohkjAMfn7DRp0kQZGRlnHK+oqNDvf/97FRYW6rLLLpMkLVq0SD169NCHH36oiy++ONJDjSrRkhMTr4mjjfn9WJkVqi+QCWXisF0bggJATY4PdrZv367MzEw1a9ZMubm5mjdvnjp16qRNmzbp1KlTysvL857bvXt3derUSevWrSPYCaChVSt2iMfE0cb8fkI1Gxeq68RrwArAORwd7AwYMECLFy/Weeedp3379un+++/XpZdeqk8++URlZWVKSkpSmzZtfJ6Tnp6usrKyeq9bVVWlqqoq78+VlZXhGL6jNaZqBeHXmN9PqGbjQjmrF48BKwDncHTOzogRI3TVVVfpggsu0LBhw/TOO+/oyJEjev311xt13Xnz5ik1NdX7lZ2dHaIRR5d4zomJBg39/VhJDK4viI31SjcA8cfRwU5tbdq00fe+9z19+eWXysjI0MmTJ3XkyBGfc8rLy/3m+NQ0d+5cVVRUeL92794dxlE7G1UrztaQ30+gxGDDkEaM8P9cJ8zqObGjN4Do5uhlrNqOHj2qr776Stddd5369eunpk2batWqVRozZowkadu2bdq1a5dyc3PrvU5ycrKSk5MjMeSowBKDszXk91NXYnBCghk8vP32d9euGUzYnTjs1I7eAKKbyzD8pT86w5w5c3TFFVfonHPO0d69e3Xvvfdqy5Yt+uyzz9ShQwdNmzZN77zzjhYvXqyUlBTdcsstkqQPPvggqNeprKxUamqqKioqlJKSEo63ghgQzm7D4eIZ84oVZhBTm2emp6DATCK28z3V1THaM9vE0iqA2qzevx0d7IwbN05r167VoUOH1KFDB/3whz/Uww8/rK5du0oymwreeuutWrp0qaqqqjRs2DA999xzAZexaiPYQSDRPOPgdp+5v1ZNnsqu0lJ7l66cPkYAzhMTwU6kEOygPtE+41BSYm4FEUhxsX3LmdEwRgDOY/X+HVUJykCkOX0PMSuioVt2NIwRQPQi2AHq4fQ9xKxoSDfmSFdERUtHbwDRiWAHqEcszDgEuyFnuHdDD8UYASAYBDtAPcI94xCJGZRgNuQMtFt6uAIeuzcNBRDbCHaAejRkxsFqABPJGRQr3Zjtzk+iozeAcKEaS1RjOZkTett4Zjsk/3tU1bwRWy1Rt6vCq77P0ykVUU74nQOIDlbv31HVQRnfiYcbglN629TVjbh2t+G6AhjPEtB990nduklpafXPoLhc3zX5C/XvtL5uzE7JT6KjN4BQY2ZH0Tez45QgIJyc2NumvgAzUFO8hoh0TxmnzOwAgFU0FQxCNAU7TgwCQi0au+laDRSCUVgojR8f2mvWx/O579njf9bJiZ87gPhGU8EYZHcCaaREY2+bcCztRLqnDBVRAGIVwU4UicYgoCEamzsS6YZ4UmgDEzt7ylARBSAWkaAcRZySQBpujeltY1c+k6dEva4lIKucMIOSn28mR8d6AjyA+MHMThSJl5b6De2ma1dDPKn+JaBgOGUGxVMRNX68+Z1AB0A0I0FZ0ZOgHE8JpIF627z2mtShw3czDwMHSl272p/U7G9mqS4ul7lctHixtH8/MygAECyqsYLglGDHSu+cYBrc2TG+UPIXOGRnS+PGmfk4NY936CAdOBD4mpEom675OW3fLt17r/n7ifTvCwBiHU0Fo4zVXBOrDe4aw19Qs2JF5HNh/OWOHDwo/exnZ85sWQl0pMjkM9Vuinf++eH9fQEA6sfMjuyf2WlI75xwzbL4C7ratZMOHTrz3EjPToSicV+oZ3as/h7ioeM1AEQay1hBsDPYcVIDvbqCrvpEcnyNadwXjnFGQydrgiwAsYxlLAereQMqL7feOyfcmy/W1bCwPpEan9TwJahwlHMH2gfLymxXuAORaAjGACASKD2PsKIicyZnyBDpmmukWbOsPS/cuSaBGhYGEolcGKsl9e3b+/4c6nLuUHSyrv33YMgQ8+dQlcfbWYYPAE5DsBNBdd2ArAh375zGBitWxtfYzsZW++/s2WPm5hQWmt9LS0M7k9HYTtbhDkTiZVsRALCKZawIaegykSfXJNxbBzQ0mLI6vlAsqXga940dW3cp94IFUlJSeJfUGtPJ2kogMnWqlJra8GZ+wQRj7F4OIB4wsxMhDVkmspprEoq9oALNmjRmfFZmMvy9B3/HnLB3U2M6WVv5e3D4sJSX539Zy8rvOl62FQEAywwYFRUVhiSjoqIibK9RWGgY5r+prX9lZxvGG2/Uf9033jCMrCzf52VlBX5eXddyucyvmtfz/NyuXeDxnT5tGMXF5vstLjaMqqozx1f72u3anXlOu3Znvl7N91X7dU6fDv79NtTp0+ZYan9ONd9Tdrb/MQXz98Dzu/C8Z6u/6+Jia9cvLg73JwUA4WX1/k2wY0Qm2LF6A/rtb63fwD3BSaCbZDD83VA9QU2gAMPfczt0CD7Is3rzt1N9gWF9Y7T696B24PT669Z/140JxgAgmli9f9NnR5HpsxPqfa3C2Z+nISXRDenR0xBO2v+rru0s6uuMHOjvQV3atze7R/vj7zOxc1sRAIgUmgoGIRzBTl1bLoTqBmS1wV6k9oJqbGfjYEXifVnRmMBQCm1wWPszaUgwBgDRhKaCNqqv8qgh+1r5u6E6KQm1sT16GsIpybW198Gyoq79zRqr9mfib28xOigDiEcEOyFmpbPujh3Wb0B1BU5Tp1obT7j780j2BB4dO0b3VgieQKSkxNzY9PBh/+e5XOYSlpWNTv39rhsSjAFArKH0PISsNnOTzBvQ+PH191Kpr2T73nvNDTrra7DXpo20bJk5a3TyZNBvx7LGdDau7z3442kcePBgeDsQR0JiojR0qPTSS+b7qv05eH5+7jlrzRTD3YsJAKIVwU4INbazbk2BAqdAAYJhSEeOmDfKWbOkFi2kX/4y8Os2REM7G+/YIb344nfnBOI5Z9w4czYkVrZCCNQ7aOxYcwlUqjsgCuW+XwAQawh2QijYPJr6GsRZCZwOHTJv+la43dLjjzc+4PE3Zk9nYyn4m3FdN/p27cyvmrKypNdeM1870OxZtG2FkJ9vBn91bXPhhGaKABCtqMZS6KqxgqmQOny4/u0Tli41l2cCadu27nwPfxITpePHzS0VghVoy4f6qn+k+p/rL/9GOvPYe+85pwrNDtGcpwQAoUbpeRBCFexY7aXzxBPmjEztc2qWoLdta+2m3hC//e13uUNW1ZV4Xbtsvr6S+0DPtcJqEFhYaOZEAQBil9X7N8tYIWRlOec3vzFzaAItwwwcGDgPpm3bho3zq6+COz+YXbQ91T+e5GsptDtwN2ZfKgBAfCLYCbFAuRUdOlhLYv7gg8CB08yZDRtj167Bnd+YxOtQJm1L1pOhnVSZFIqNWgEADUewEwb1JZsGk8QcKHD61a+C36k8MVG6+Wbr53vG0tDzQt38sDHJ0HYoKor+EnkAiHYxE+w8++yzysnJUbNmzTRgwABt2LDB1vHUXs7x3HyDXYapL3Cq78Zfl9mzg09ObszSUTiWnaKlMqm+PknRWCIPANEqJhKUX3vtNU2cOFELFy7UgAEDtGDBAi1btkzbtm1TWlpawOdHYiNQj1BvCCr5r4KqLTHRDHTmz4/smMPxfmte26mVSeHcqBUAYIqraqwBAwbowgsv1DPPPCNJqq6uVnZ2tm655RbdcccdAZ8fyWBHCs+O1LVv/AMGSC+8YCYjd+1qLl01pNw8FGOOxx24nbRRKwDEqripxjp58qQ2bdqkvLw877GEhATl5eVp3bp1No6sbuFYhqm9bNa8uVnl9PTT5vfGBDqNHXO0LDuFkpM2agWAeBf1G4EePHhQbrdb6enpPsfT09P1xRdf+H1OVVWVqqqqvD9XVlaGdYz+ROOO1I0ZczS+38agRB4AnCPqg52GmDdvnu6//367hxGVO1I3ZszR+H4bylMiHyhXyUkl8gAQq6J+Gat9+/ZKTExUeXm5z/Hy8nJlZGT4fc7cuXNVUVHh/dq9e3ckhoo4Em0l8gAQy6I+2ElKSlK/fv20atUq77Hq6mqtWrVKubm5fp+TnJyslJQUny/UjaZ4DROPuUoA4EQxsYw1e/ZsTZo0Sf3799dFF12kBQsW6NixY5oyZYrdQ4t6gTb/RP3iLVcJAJwoJoKdq6++WgcOHNA999yjsrIy9e3bV3/729/OSFpGcOra/NPTFI/ZCWviKVcJAJwoJvrsNFak++xEg2hoiufkpoIAgPCLmz47CI9Qb+AZauw5BQCwimAHfjm5KR57TgEAgkGwA7+c2hTP7TYTpv0tvnqOFRRQMQYA+A7BDvzyNMWrazd1l0vKzo58UzynL68BAJyHYAd+ObUpnpOX1wAAzkSw43ChbugXzPWc2BTPqctrAADnovRczi09D3VDv4Zez0kl3p6S+EB7TtlZEg8AiAyr92+CHTkz2KmroZ9nCSnYmZVQX89Onvci+b6faHwvAICGo89OFAt1xVGsVTA5cXkNAOBcBDsOFOqKo1isYMrPl3bskIqLpcJC83tpKYEOAOBMMbE3VqwJdcVRrFYwsecUAMAKgh0HCnXFUSQrmJyUzAwAgMQyliOFuqFfpBoEsl8VAMCJCHYcKNQN/SLRIJD9qgAATkWw41ChrjgKZwVTrFV7AQBiC3125Mw+Ox6hzoEJR05NSYm5ZBVIcTEJxQCA0LF6/yZB2eFCXXEUjgqmWK32AgDEBpax0GjsVwUAcDKCHTRapKq9AABoCIIdNFokqr0AAGgogh2EBPtVAQCcigRlhEx+vjR6NB2UAQDOQrCDkGK/KgCA07CMBQAAYhrBDgAAiGkEOwAAIKYR7AAAgJhGsAMAAGIawQ4AAIhpBDsAACCmEewAAICYRrADAABiGh2UJRmGIUmqrKy0eSQAAMAqz33bcx+vC8GOpG+//VaSlJ2dbfNIAABAsL799lulpqbW+bjLCBQOxYHq6mrt3btXrVu3lsvlavT1KisrlZ2drd27dyslJSUEI0R9+Lwjh886svi8I4vPO7JC8XkbhqFvv/1WmZmZSkioOzOHmR1JCQkJysrKCvl1U1JS+A8mgvi8I4fPOrL4vCOLzzuyGvt51zej40GCMgAAiGkEOwAAIKYR7IRBcnKy7r33XiUnJ9s9lLjA5x05fNaRxecdWXzekRXJz5sEZQAAENOY2QEAADGNYAcAAMQ0gh0AABDTCHYAAEBMI9gJsWeffVY5OTlq1qyZBgwYoA0bNtg9pJg0b948XXjhhWrdurXS0tJ05ZVXatu2bXYPK248+uijcrlcKigosHsoMWvPnj269tpr1a5dOzVv3ly9e/fW//t//8/uYcUkt9utu+++W507d1bz5s3VtWtXPfjggwH3W4I1a9eu1RVXXKHMzEy5XC69+eabPo8bhqF77rlHHTt2VPPmzZWXl6ft27eHdAwEOyH02muvafbs2br33nu1efNm9enTR8OGDdP+/fvtHlrMWbNmjaZPn64PP/xQK1eu1KlTp3T55Zfr2LFjdg8t5m3cuFEvvPCCLrjgAruHErP+93//V5dccomaNm2qd999V5999pl+85vf6KyzzrJ7aDHpscce0/PPP69nnnlGn3/+uR577DHNnz9fTz/9tN1DiwnHjh1Tnz599Oyzz/p9fP78+Xrqqae0cOFCrV+/Xi1bttSwYcN04sSJ0A3CQMhcdNFFxvTp070/u91uIzMz05g3b56No4oP+/fvNyQZa9assXsoMe3bb781unXrZqxcudIYNGiQMXPmTLuHFJNuv/1244c//KHdw4gbI0eONK6//nqfY/n5+caECRNsGlHskmQsX77c+3N1dbWRkZFhPP74495jR44cMZKTk42lS5eG7HWZ2QmRkydPatOmTcrLy/MeS0hIUF5entatW2fjyOJDRUWFJKlt27Y2jyS2TZ8+XSNHjvT5e47Q+8tf/qL+/fvrqquuUlpamr7//e/rpZdesntYMWvgwIFatWqV/vOf/0iSPvroI73//vsaMWKEzSOLfaWlpSorK/P5f0pqaqoGDBgQ0nsnG4GGyMGDB+V2u5Wenu5zPD09XV988YVNo4oP1dXVKigo0CWXXKLzzz/f7uHErFdffVWbN2/Wxo0b7R5KzPv666/1/PPPa/bs2brzzju1ceNG/eIXv1BSUpImTZpk9/Bizh133KHKykp1795diYmJcrvdevjhhzVhwgS7hxbzysrKJMnvvdPzWCgQ7CDqTZ8+XZ988onef/99u4cSs3bv3q2ZM2dq5cqVatasmd3DiXnV1dXq37+/HnnkEUnS97//fX3yySdauHAhwU4YvP7663rllVdUWFioXr16acuWLSooKFBmZiafd4xgGStE2rdvr8TERJWXl/scLy8vV0ZGhk2jin0zZszQ22+/reLiYmVlZdk9nJi1adMm7d+/Xz/4wQ/UpEkTNWnSRGvWrNFTTz2lJk2ayO122z3EmNKxY0f17NnT51iPHj20a9cum0YU22677TbdcccdGjdunHr37q3rrrtOs2bN0rx58+weWszz3B/Dfe8k2AmRpKQk9evXT6tWrfIeq66u1qpVq5Sbm2vjyGKTYRiaMWOGli9frtWrV6tz5852DymmDR06VFu3btWWLVu8X/3799eECRO0ZcsWJSYm2j3EmHLJJZec0UrhP//5j8455xybRhTbjh8/roQE39thYmKiqqurbRpR/OjcubMyMjJ87p2VlZVav359SO+dLGOF0OzZszVp0iT1799fF110kRYsWKBjx45pypQpdg8t5kyfPl2FhYVasWKFWrdu7V3bTU1NVfPmzW0eXexp3br1GflQLVu2VLt27ciTCoNZs2Zp4MCBeuSRR/Szn/1MGzZs0IsvvqgXX3zR7qHFpCuuuEIPP/ywOnXqpF69eunf//63nnjiCV1//fV2Dy0mHD16VF9++aX359LSUm3ZskVt27ZVp06dVFBQoIceekjdunVT586ddffddyszM1NXXnll6AYRsrouGIZhGE8//bTRqVMnIykpybjooouMDz/80O4hxSRJfr8WLVpk99DiBqXn4fXWW28Z559/vpGcnGx0797dePHFF+0eUsyqrKw0Zs6caXTq1Mlo1qyZ0aVLF+NXv/qVUVVVZffQYkJxcbHf/19PmjTJMAyz/Pzuu+820tPTjeTkZGPo0KHGtm3bQjoGl2HQIhIAAMQucnYAAEBMI9gBAAAxjWAHAADENIIdAAAQ0wh2AABATCPYAQAAMY1gBwAAxDSCHQAAENMIdgDEFLfbrYEDByo/P9/neEVFhbKzs/WrX/3KppEBsAsdlAHEnP/85z/q27evXnrpJU2YMEGSNHHiRH300UfauHGjkpKSbB4hgEgi2AEQk5566indd999+vTTT7VhwwZdddVV2rhxo/r06WP30ABEGMEOgJhkGIYuu+wyJSYmauvWrbrlllt011132T0sADYg2AEQs7744gv16NFDvXv31ubNm9WkSRO7hwTABiQoA4hZf/jDH9SiRQuVlpbqm2++sXs4AGzCzA6AmPTBBx9o0KBB+sc//qGHHnpIkvTPf/5TLpfL5pEBiDRmdgDEnOPHj2vy5MmaNm2ahgwZot///vfasGGDFi5caPfQANiAmR0AMWfmzJl655139NFHH6lFixaSpBdeeEFz5szR1q1blZOTY+8AAUQUwQ6AmLJmzRoNHTpUJSUl+uEPf+jz2LBhw3T69GmWs4A4Q7ADAABiGjk7AAAgphHsAACAmEawAwAAYhrBDgAAiGkEOwAAIKYR7AAAgJhGsAMAAGIawQ4AAIhpBDsAACCmEewAAICYRrADAABiGsEOAACIaf8fRY1jq9TIav4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 310.88\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LM4d4oWW6wzz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}